{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class CustomLogger(object):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.deltatime = []\n",
    "        self.n_epochs = 0\n",
    "        self.out = []\n",
    "        \n",
    "    def update(self, loss, val_loss, delta_time,\n",
    "               model, loss_fn, train_loader, val_loader):\n",
    "        self.losses.append(loss)\n",
    "        self.deltatime.append(delta_time)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.n_epochs += 1\n",
    "\n",
    "    def output(self):\n",
    "        s = f'epoch ({self.n_epochs}) ' \\\n",
    "            f'time: {self.deltatime[-1]} ' \\\n",
    "            f'loss: {self.losses[-1]} ' \n",
    "        if self.val_losses[-1] is not None:\n",
    "            s += f'val_loss: {self.val_losses[-1]}'\n",
    "        self.out.append(s)\n",
    "        print(s)\n",
    "\n",
    "\n",
    "class MyLogger(CustomLogger):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.p = []\n",
    "    \n",
    "    def update(self, delta_time, loss, val_loss,\n",
    "               model, loss_fn, train_loader, val_loader):\n",
    "        super().update(delta_time, loss, val_loss,\n",
    "                       model, loss_fn, train_loader, val_loader)\n",
    "        p = model.state_dict()\n",
    "        self.p.append([p['linear.bias'].item(), p['linear.weight'].item()])\n",
    "\n",
    "    def output(self, formatstring=''):\n",
    "        s = f'epoch ({self.n_epochs}) ' \\\n",
    "            f'time: {self.deltatime[-1]} ' \\\n",
    "            f'loss: {self.losses[-1]} ' \\\n",
    "            f'p: {self.p[-1]}'\n",
    "        if self.val_losses[-1] is not None:\n",
    "            s += f'val_loss: {self.val_losses[-1]}' \n",
    "        print(s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTemplete():\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.stats = {'losses': [],\n",
    "                       'val_losses': [],\n",
    "                       'delta_time': [],\n",
    "                       'n_epochs': 0}\n",
    "\n",
    "    def log_update(self, delta_time, loss, val_loss):\n",
    "        self.stats['delta_time'].append(delta_time)\n",
    "        self.stats['losses'].append(loss)\n",
    "        self.stats['val_losses'].append(val_loss)\n",
    "        self.stats['n_epochs'] += 1\n",
    "\n",
    "    def log_output(self, verbose=0, formatstr=''):\n",
    "        s = [f'epoch ({{{formatstr}}})'.format(self.stats['n_epochs'], ),\n",
    "             f'time: {{{formatstr}}}'.format(self.stats['delta_time'][-1]),\n",
    "             f'loss: {{{formatstr}}}'.format(self.stats['losses'][-1])]\n",
    "        if self.stats['val_losses'][-1] is not None:\n",
    "            s.append(f'val_loss: {{{formatstr}}}'.format(self.stats['val_losses'][-1]))\n",
    "        if verbose == 1:\n",
    "            print(' '.join(s))\n",
    "        return s\n",
    "    \n",
    "    def _minibatch_one_epoch(self, dataloader, val=False):\n",
    "        if val is False:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        # dataloader = self.val_loader if val else self.train_loader\n",
    "\n",
    "        losses = []\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            yhat = self.model(X_batch)\n",
    "            loss = self.loss_fn(yhat, y_batch)\n",
    "            if val is False:\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "        return np.mean(losses)\n",
    "    \n",
    "    def train(self, train_loader, val_loader=None, epoch_num=10, verbose=0):\n",
    "        for _ in range(epoch_num):\n",
    "            start_time = time.time()\n",
    "            loss = self._minibatch_one_epoch(train_loader, val=False)\n",
    "            end_time = time.time()\n",
    "            delta_time = end_time - start_time\n",
    "\n",
    "            val_loss = self._minibatch_one_epoch(val_loader, val=True) if val_loader is not None else None\n",
    "            self.log_update(delta_time, loss, val_loss)\n",
    "            self.log_output(verbose=verbose)\n",
    "        # return self.logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.nn.modules import Linear\n",
    "from torch.nn import MSELoss\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class BetterLR(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.linear = Linear(in_features=1, out_features=1)\n",
    "        self.linear.bias = torch.nn.Parameter(torch.tensor([1.0], dtype=float))\n",
    "        self.linear.weight = torch.nn.Parameter(torch.tensor([[1.5]], dtype=float))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=float).reshape(-1, 1)\n",
    "        self.y = torch.tensor(y, dtype=float).reshape(-1, 1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    \n",
    "RANDOMSEED = 42\n",
    "np.random.seed(RANDOMSEED)\n",
    "X = np.random.rand(100)\n",
    "y = 2.3 + 1.2 * X + np.random.randn(100) * 0.1\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15,\n",
    "                                                    random_state=RANDOMSEED)\n",
    "    \n",
    "train_data = MyData(X_train, y_train)\n",
    "# val_data = MyData(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=False)\n",
    "# val_loader = DataLoader(dataset=val_data, batch_size=32)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1.000) time: 0.003 loss: 0.626\n",
      "epoch (2.000) time: 0.004 loss: 0.062\n",
      "epoch (3.000) time: 0.004 loss: 0.046\n",
      "epoch (4.000) time: 0.003 loss: 0.040\n",
      "epoch (5.000) time: 0.002 loss: 0.035\n",
      "epoch (6.000) time: 0.002 loss: 0.031\n",
      "epoch (7.000) time: 0.004 loss: 0.027\n",
      "epoch (8.000) time: 0.003 loss: 0.024\n",
      "epoch (9.000) time: 0.002 loss: 0.022\n",
      "epoch (10.000) time: 0.002 loss: 0.020\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.2\n",
    "model = BetterLR().to(device)\n",
    "optimizer = SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# msg = MyLogger()\n",
    "mm = ModelTemplete(model, MSELoss(reduction='mean'), optimizer)\n",
    "\n",
    "\n",
    "mm.train(train_loader, epoch_num=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(ModelTemplete):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        super().__init__(model, loss_fn, optimizer)\n",
    "        self.states['p'] = []\n",
    "\n",
    "    def log_update(self, delta_time, loss, val_loss):\n",
    "        super().log_update(delta_time, loss, val_loss)\n",
    "        p = self.model.state_dict()\n",
    "        self.states['p'].append([p['linear.bias'].item(), p['linear.weight'].item()])\n",
    "\n",
    "\n",
    "    def log_output(self, verbose=0):\n",
    "        s = super().log_output(verbose=0, formatstr=':.6f')\n",
    "        s.append(f'p: [{self.states['p'][-1][0]}, {self.states['p'][-1][1]}]')\n",
    "        if verbose==1:\n",
    "            print(' '.join(s))\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1.000000) time: 0.002618 loss: 0.626386 p: [1.8277028504755573, 1.8368193572906044]\n",
      "epoch (2.000000) time: 0.002110 loss: 0.061719 p: [1.9607104449826838, 1.8293981130981023]\n",
      "epoch (3.000000) time: 0.001996 loss: 0.045990 p: [2.001626059409397, 1.7815077539441087]\n",
      "epoch (4.000000) time: 0.002000 loss: 0.040067 p: [2.0286935704191, 1.7321715193480243]\n",
      "epoch (5.000000) time: 0.002017 loss: 0.035140 p: [2.0522055690695757, 1.686138097785071]\n",
      "epoch (6.000000) time: 0.002005 loss: 0.030973 p: [2.0736381185747943, 1.6437403254745735]\n",
      "epoch (7.000000) time: 0.001977 loss: 0.027453 p: [2.0933134526016604, 1.6047617600958677]\n",
      "epoch (8.000000) time: 0.002109 loss: 0.024479 p: [2.111393711486754, 1.5689357968513453]\n",
      "epoch (9.000000) time: 0.001896 loss: 0.021968 p: [2.1280105514943686, 1.5360086358936902]\n",
      "epoch (10.000000) time: 0.002096 loss: 0.019847 p: [2.143282725696795, 1.505745878510758]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.2\n",
    "model = BetterLR().to(device)\n",
    "optimizer = SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# msg = MyLogger()\n",
    "mm = MyModel(model, MSELoss(reduction='mean'), optimizer)\n",
    "\n",
    "mm.train(train_loader, epoch_num=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Da = MyData(X, y)\n",
    "dl = DataLoader(Da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = MyData(X, y)\n",
    "train_data, val_data = random_split(dataset, [.85, .15], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1) time: 0.004000 loss: 0.627555 p: [1.828082, 1.851994] \n",
      "epoch (2) time: 0.003000 loss: 0.067947 p: [1.972544, 1.843260] \n",
      "epoch (3) time: 0.002035 loss: 0.049432 p: [2.016118, 1.792544] \n",
      "epoch (4) time: 0.001968 loss: 0.041331 p: [2.036865, 1.736838] \n",
      "epoch (5) time: 0.002075 loss: 0.035494 p: [2.055019, 1.686687] \n",
      "epoch (6) time: 0.002017 loss: 0.031306 p: [2.071784, 1.641176] \n",
      "epoch (7) time: 0.001904 loss: 0.028636 p: [2.099186, 1.604492] \n",
      "epoch (8) time: 0.003001 loss: 0.025880 p: [2.116329, 1.565389] \n",
      "epoch (9) time: 0.003000 loss: 0.022410 p: [2.119514, 1.524232] \n",
      "epoch (10) time: 0.002001 loss: 0.019656 p: [2.137073, 1.495972] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "lr = 0.2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = BetterLR().to(device)\n",
    "optimizer = SGD(model.parameters(), lr=lr)\n",
    "msg = MyLogger()\n",
    "\n",
    "mm = ModelTemplete(model, MSELoss(reduction='mean'), optimizer, msg)\n",
    "mm.set_loaders(train_loader, val_loader)\n",
    "\n",
    "mm.train(epoch_num=10, verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'deltatime',\n",
       " 'losses',\n",
       " 'n_epochs',\n",
       " 'output',\n",
       " 'p',\n",
       " 'update',\n",
       " 'val_losses']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(msg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.stats = {\"nn\": [1,2,2]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'losses': [0.6263859546406714,\n",
       "  0.06171929297399448,\n",
       "  0.045990025048784,\n",
       "  0.04006740409547522,\n",
       "  0.03513987757810646,\n",
       "  0.03097301278504304,\n",
       "  0.027452771476570853,\n",
       "  0.02447947611654223,\n",
       "  0.021968262094932956,\n",
       "  0.019847355986687194],\n",
       " 'val_losses': [None, None, None, None, None, None, None, None, None, None],\n",
       " 'delta_time': [0.002618074417114258,\n",
       "  0.0021097660064697266,\n",
       "  0.001996278762817383,\n",
       "  0.0019998550415039062,\n",
       "  0.0020172595977783203,\n",
       "  0.0020046234130859375,\n",
       "  0.0019769668579101562,\n",
       "  0.002109050750732422,\n",
       "  0.0018961429595947266,\n",
       "  0.002095937728881836],\n",
       " 'n_epochs': 10,\n",
       " 'p': [[1.8277028504755573, 1.8368193572906044],\n",
       "  [1.9607104449826838, 1.8293981130981023],\n",
       "  [2.001626059409397, 1.7815077539441087],\n",
       "  [2.0286935704191, 1.7321715193480243],\n",
       "  [2.0522055690695757, 1.686138097785071],\n",
       "  [2.0736381185747943, 1.6437403254745735],\n",
       "  [2.0933134526016604, 1.6047617600958677],\n",
       "  [2.111393711486754, 1.5689357968513453],\n",
       "  [2.1280105514943686, 1.5360086358936902],\n",
       "  [2.143282725696795, 1.505745878510758]]}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
