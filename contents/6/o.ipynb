{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ModelTemplate():\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.stats = {'losses': [],\n",
    "                      'val_losses': [],\n",
    "                      'train_time': [],\n",
    "                      'val_time': [],\n",
    "                      'n_epochs': 0}\n",
    "\n",
    "    def set_seed(self, seed=42):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def save(self, filename='model.pth'):\n",
    "        model_state = {\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'stats': self.stats\n",
    "        }\n",
    "        torch.save(model_state, filename)\n",
    "\n",
    "    def load(self, filename='model.pth'):\n",
    "        model_state = torch.load(filename, weights_only=False)\n",
    "        self.model.load_state_dict(model_state['model'])\n",
    "        self.optimizer.load_state_dict(model_state['optimizer'])\n",
    "        self.stats = model_state['stats']\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "    def log_update(self, train_time, loss, val_time, val_loss, train_loader, val_loader):\n",
    "        self.stats['train_time'].append(train_time)\n",
    "        self.stats['losses'].append(loss)\n",
    "        self.stats['val_time'].append(val_time)\n",
    "        self.stats['val_losses'].append(val_loss)\n",
    "        self.stats['n_epochs'] += 1\n",
    "\n",
    "    def log_output(self, verbose=1, formatstr=''):\n",
    "        s = [f'epoch {self.stats['n_epochs']}',\n",
    "             f'train_time: {{{formatstr}}}'.format(self.stats['train_time'][-1]),\n",
    "             f'loss: {{{formatstr}}}'.format(self.stats['losses'][-1])]\n",
    "        if self.stats['val_losses'][-1] is not None:\n",
    "            s.append(f'val_time: {{{formatstr}}}'.format(self.stats['val_time'][-1]))\n",
    "            s.append(f'val_loss: {{{formatstr}}}'.format(self.stats['val_losses'][-1]))\n",
    "        if verbose == 1:\n",
    "            print(' '.join(s))\n",
    "        return s\n",
    "    \n",
    "    class metrics():\n",
    "        def __init__(self):\n",
    "            self.acc = []\n",
    "        \n",
    "        def update(self, yhat, y):\n",
    "            self.acc.append((yhat==y).sum().item())\n",
    "\n",
    "\n",
    "    def _train_one_epoch(self, dataloader):\n",
    "        self.model.train()\n",
    "\n",
    "        losses = []\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            yhat = self.model(X_batch)\n",
    "            loss = self.loss_fn(yhat, y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "        return np.mean(losses)\n",
    "\n",
    "    def _eval_one_epoch(self, dataloader):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            yhat = self.model(X_batch)\n",
    "            loss = self.loss_fn(yhat, y_batch)\n",
    "            losses.append(loss.item())\n",
    "        return np.mean(losses)\n",
    "\n",
    "    def train(self, train_loader, val_loader=None, epoch_num=10, verbose=0, SEED=42):\n",
    "        self.set_seed(SEED)\n",
    "        for _ in range(epoch_num):\n",
    "            start_time = time.time()\n",
    "            loss = self._train_one_epoch(train_loader)\n",
    "            end_time = time.time()\n",
    "            train_time = end_time - start_time\n",
    "\n",
    "            val_loss = None\n",
    "            val_time = None\n",
    "            if val_loader is not None:\n",
    "                start_time = time.time()\n",
    "                val_loss = self._eval_one_epoch(val_loader)\n",
    "                end_time = time.time()\n",
    "                val_time = end_time - start_time\n",
    "\n",
    "            self.log_update(train_time, loss, val_time, val_loss, train_loader, val_loader)\n",
    "            self.log_output(verbose=verbose)\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        X_tensor = torch.as_tensor(X, dtype=float)\n",
    "        y_tensor = self.model(X_tensor.to(self.device))\n",
    "        self.model.train()\n",
    "        y = y_tensor.detach().cpu().numpy()\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class __MyModel__(ModelTemplate):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        super().__init__(model, loss_fn, optimizer)\n",
    "        self.stats['p'] = []\n",
    "\n",
    "    def log_update(self, train_time, loss, val_time, val_loss):\n",
    "        super().log_update(train_time, loss, val_time, val_loss)\n",
    "        p = self.model.state_dict()\n",
    "        self.stats['p'].append([p['linear.bias'].item(), p['linear.weight'].item()])\n",
    "\n",
    "    def log_output(self, verbose=0):\n",
    "        s = super().log_output(verbose=0, formatstr=':.6f')\n",
    "        s.append(f'p: [{self.stats['p'][-1][0]:.6f}, {self.stats['p'][-1][1]:.6f}]')\n",
    "        if verbose == 1:\n",
    "            print(' '.join(s))\n",
    "        return s\n",
    "\n",
    "\n",
    "class __MyData__(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=float).reshape(-1, 1)\n",
    "        self.y = torch.tensor(y, dtype=float).reshape(-1, 1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data'\n",
    "# df = pd.read_csv(url, sep='\\\\s+', header=None)\n",
    "# df = df.replace(\"?\", np.NaN)\n",
    "\n",
    "# df.fillna(0, inplace=True)\n",
    "# df = df.drop(columns=[2, 24, 25, 26, 27])\n",
    "# df[23] = df[23].replace({1: 1, 2: 0})\n",
    "# X = df.iloc[:, :-1].to_numpy().astype(float)\n",
    "# y = df[23].to_numpy().astype(int)\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "mms = StandardScaler()\n",
    "X_train = mms.fit_transform(X_train, y_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=float)\n",
    "        self.y = torch.tensor(y, dtype=float).reshape(-1, 1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "\n",
    "train_set = MyData(X_train, y_train)\n",
    "val_set = MyData(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59635346, -0.51713419],\n",
       "       [ 0.3937561 , -1.35813138],\n",
       "       [ 1.33167696, -1.16636502],\n",
       "       [-1.52208256, -0.33314461],\n",
       "       [-1.20280449,  0.64649722],\n",
       "       [-0.65443973,  0.48658224],\n",
       "       [ 1.00612744, -1.81018492],\n",
       "       [-0.28996374, -1.5477782 ],\n",
       "       [ 0.03349394, -0.65113935],\n",
       "       [-0.94744907,  0.76650095],\n",
       "       [ 0.61340448, -1.50292036],\n",
       "       [ 1.90666775, -0.49298432],\n",
       "       [-1.51519782, -0.37657626],\n",
       "       [ 0.83679088,  1.55233811],\n",
       "       [-0.5673415 ,  0.20360244],\n",
       "       [ 1.34884731, -0.7930775 ],\n",
       "       [-0.19406929,  0.92544509],\n",
       "       [-1.57387163, -1.21907634],\n",
       "       [-0.72861616,  1.22434395],\n",
       "       [ 1.36732327,  0.53003428],\n",
       "       [-1.16333041,  1.31264925],\n",
       "       [-0.49927845,  1.19894001],\n",
       "       [ 1.24056139, -1.50978838],\n",
       "       [-0.31599591, -0.18511142],\n",
       "       [-0.00410317, -0.69877045],\n",
       "       [-0.39572336,  1.22179345],\n",
       "       [-1.59788135,  1.05926647],\n",
       "       [-0.95127788,  1.20886702],\n",
       "       [ 0.2648369 , -1.79475603],\n",
       "       [-0.84669415,  0.57440659],\n",
       "       [-2.01025248,  0.25426273],\n",
       "       [-0.68877598,  1.63174209],\n",
       "       [-0.81948226, -0.13096199],\n",
       "       [-0.25959788,  0.96883437],\n",
       "       [-0.9448469 ,  1.42130415],\n",
       "       [ 0.05654946,  1.19227583],\n",
       "       [-0.19697736,  0.86227843],\n",
       "       [ 0.10293951,  0.11073556],\n",
       "       [-1.10929041,  0.68244118],\n",
       "       [ 0.17772649,  0.80935964],\n",
       "       [ 0.53099826, -1.71623851],\n",
       "       [ 0.50765113,  1.86604068],\n",
       "       [ 0.69070656, -1.07181241],\n",
       "       [-0.39213398, -1.09063717],\n",
       "       [ 0.18001833, -1.20377141],\n",
       "       [ 0.33221211, -0.19699459],\n",
       "       [-0.96156663, -0.84810398],\n",
       "       [ 1.82998888,  0.65461827],\n",
       "       [-0.50673058, -0.27452625],\n",
       "       [-0.45771551,  0.49445865],\n",
       "       [ 0.2314398 ,  0.80672703],\n",
       "       [ 0.77520027,  0.54793829],\n",
       "       [ 1.16651035, -0.53024088],\n",
       "       [ 0.90647024, -1.27723826],\n",
       "       [ 1.61393402, -0.16564036],\n",
       "       [-1.27110231, -0.67144823],\n",
       "       [-0.80001929,  0.8500904 ],\n",
       "       [ 1.83249665, -0.5320639 ],\n",
       "       [-0.31387723, -0.56854037],\n",
       "       [ 1.70753925, -0.97251755],\n",
       "       [-1.98598605, -0.14608289],\n",
       "       [-0.01583184, -0.78153782],\n",
       "       [ 0.76739167,  0.47170384],\n",
       "       [ 1.5526051 , -0.47315054],\n",
       "       [ 0.45300973, -0.58150638],\n",
       "       [ 0.27289479,  0.29464525],\n",
       "       [-0.13692804, -1.59126758],\n",
       "       [ 1.72939165, -0.24810312],\n",
       "       [ 0.53182616, -1.15783589],\n",
       "       [ 1.4118482 ,  0.31439228],\n",
       "       [-0.1751801 ,  0.02570472],\n",
       "       [ 0.22281591,  2.17885977],\n",
       "       [-0.7004349 ,  1.15638464],\n",
       "       [ 0.14340787,  0.06899817],\n",
       "       [-0.28467735,  1.76048387],\n",
       "       [-1.3702369 , -1.09617967],\n",
       "       [-0.19749714,  1.61135463],\n",
       "       [ 1.86682733,  0.32102674],\n",
       "       [-1.68139218, -0.18335051],\n",
       "       [ 0.90912128, -0.80123927]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "xxx = TensorDataset(torch.as_tensor(X_train))\n",
    "yyy = TensorDataset(torch.as_tensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.5964, -0.5171], dtype=torch.float64),)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.modules import Linear\n",
    "\n",
    "class LoR(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.linear = Linear(in_features=2, out_features=1, dtype=float)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        # pred = self.activation(self.linear(X))\n",
    "        pred = self.linear(X)\n",
    "        # return (pred >= 0).float()\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRModel(ModelTemplate):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        super().__init__(model, loss_fn, optimizer)\n",
    "        self.stats['acc_train'] = []\n",
    "        self.stats['acc_val'] = []\n",
    "\n",
    "    def compute_acc(self, dataloader):\n",
    "        with torch.no_grad():\n",
    "            acc = []\n",
    "            for X_batch, y_batch in dataloader:\n",
    "                yhat = torch.sigmoid(self.model(X_batch))\n",
    "                y_pred = (yhat>=0.5).to(float)\n",
    "                acc.append((y_pred==y_batch).sum().item())\n",
    "            # print(acc_train)\n",
    "        return np.sum(acc)/len(dataloader.dataset)\n",
    "\n",
    "    def log_update(self, train_time, loss, val_time, val_loss, train_loader, val_loader):\n",
    "        super().log_update(train_time, loss, val_time, val_loss, train_loader, val_loader)\n",
    "        acc_train = self.compute_acc(train_loader)\n",
    "        acc_val = self.compute_acc(val_loader)\n",
    "        self.stats['acc_train'].append(acc_train)\n",
    "        self.stats['acc_val'].append(acc_val)\n",
    "\n",
    "\n",
    "        # p = self.model.state_dict()\n",
    "        # self.stats['acc'].append([p['linear.bias'].item(), p['linear.weight'].item()])\n",
    "\n",
    "    def log_output(self, verbose=0):\n",
    "        s = super().log_output(verbose=0, formatstr=':.6f')\n",
    "        s.append(f'acc_train: {self.stats['acc_train'][-1]:.6f}')\n",
    "        s.append(f'acc_val: {self.stats['acc_val'][-1]:.6f}')\n",
    "        # s.append(f'p: [{self.stats['p'][-1][0]:.6f}, {self.stats['p'][-1][1]:.6f}]')\n",
    "        if verbose == 1:\n",
    "            print(' '.join(s))\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = train_loader.dataset[0][0]\n",
    "\n",
    "(ttt<-0.55).to(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_time: 0.002500 loss: 0.583988 val_time: 0.001504 val_loss: 0.528253 acc_train: 0.687500 acc_val: 0.750000\n",
      "epoch 2 train_time: 0.003004 loss: 0.544656 val_time: 0.001507 val_loss: 0.490200 acc_train: 0.725000 acc_val: 0.750000\n",
      "epoch 3 train_time: 0.003499 loss: 0.513808 val_time: 0.001000 val_loss: 0.459465 acc_train: 0.762500 acc_val: 0.750000\n",
      "epoch 4 train_time: 0.004028 loss: 0.490238 val_time: 0.000000 val_loss: 0.434522 acc_train: 0.762500 acc_val: 0.750000\n",
      "epoch 5 train_time: 0.002996 loss: 0.470588 val_time: 0.001306 val_loss: 0.413784 acc_train: 0.787500 acc_val: 0.850000\n",
      "epoch 6 train_time: 0.002999 loss: 0.455354 val_time: 0.000000 val_loss: 0.396341 acc_train: 0.787500 acc_val: 0.850000\n",
      "epoch 7 train_time: 0.003015 loss: 0.442161 val_time: 0.000506 val_loss: 0.381378 acc_train: 0.787500 acc_val: 0.850000\n",
      "epoch 8 train_time: 0.004508 loss: 0.431538 val_time: 0.001000 val_loss: 0.368658 acc_train: 0.800000 acc_val: 0.850000\n",
      "epoch 9 train_time: 0.003007 loss: 0.423078 val_time: 0.000999 val_loss: 0.357589 acc_train: 0.800000 acc_val: 0.850000\n",
      "epoch 10 train_time: 0.003774 loss: 0.415550 val_time: 0.001034 val_loss: 0.347798 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 11 train_time: 0.003506 loss: 0.409800 val_time: 0.000000 val_loss: 0.339239 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 12 train_time: 0.003011 loss: 0.404439 val_time: 0.000000 val_loss: 0.331551 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 13 train_time: 0.004085 loss: 0.399152 val_time: 0.001007 val_loss: 0.324653 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 14 train_time: 0.002000 loss: 0.395443 val_time: 0.000999 val_loss: 0.318408 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 15 train_time: 0.003522 loss: 0.391562 val_time: 0.000000 val_loss: 0.312845 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 16 train_time: 0.003505 loss: 0.388744 val_time: 0.001006 val_loss: 0.307758 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 17 train_time: 0.004012 loss: 0.385834 val_time: 0.000000 val_loss: 0.303090 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 18 train_time: 0.003023 loss: 0.383823 val_time: 0.001045 val_loss: 0.298812 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 19 train_time: 0.004508 loss: 0.381274 val_time: 0.004290 val_loss: 0.294840 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 20 train_time: 0.003507 loss: 0.379619 val_time: 0.001008 val_loss: 0.291185 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 21 train_time: 0.004023 loss: 0.377856 val_time: 0.000000 val_loss: 0.287807 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 22 train_time: 0.003033 loss: 0.376156 val_time: 0.001180 val_loss: 0.284632 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 23 train_time: 0.003001 loss: 0.374744 val_time: 0.001026 val_loss: 0.281722 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 24 train_time: 0.003572 loss: 0.373640 val_time: 0.001000 val_loss: 0.278988 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 25 train_time: 0.004079 loss: 0.372312 val_time: 0.000000 val_loss: 0.276432 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 26 train_time: 0.003002 loss: 0.371661 val_time: 0.000996 val_loss: 0.274017 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 27 train_time: 0.004022 loss: 0.371195 val_time: 0.000000 val_loss: 0.271807 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 28 train_time: 0.002506 loss: 0.370171 val_time: 0.001006 val_loss: 0.269707 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 29 train_time: 0.004007 loss: 0.368741 val_time: 0.000000 val_loss: 0.267695 acc_train: 0.812500 acc_val: 0.850000\n",
      "epoch 30 train_time: 0.002540 loss: 0.368096 val_time: 0.000995 val_loss: 0.265834 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 31 train_time: 0.005020 loss: 0.367788 val_time: 0.001008 val_loss: 0.264072 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 32 train_time: 0.003001 loss: 0.366918 val_time: 0.001506 val_loss: 0.262383 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 33 train_time: 0.004537 loss: 0.367190 val_time: 0.001000 val_loss: 0.260777 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 34 train_time: 0.004017 loss: 0.366243 val_time: 0.001000 val_loss: 0.259291 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 35 train_time: 0.005353 loss: 0.365999 val_time: 0.000000 val_loss: 0.257874 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 36 train_time: 0.002549 loss: 0.364988 val_time: 0.001235 val_loss: 0.256532 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 37 train_time: 0.004004 loss: 0.364841 val_time: 0.000999 val_loss: 0.255260 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 38 train_time: 0.003514 loss: 0.364328 val_time: 0.001002 val_loss: 0.254068 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 39 train_time: 0.003509 loss: 0.363944 val_time: 0.001510 val_loss: 0.252881 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 40 train_time: 0.003000 loss: 0.363615 val_time: 0.001506 val_loss: 0.251749 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 41 train_time: 0.002510 loss: 0.363260 val_time: 0.001003 val_loss: 0.250705 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 42 train_time: 0.005514 loss: 0.363657 val_time: 0.000506 val_loss: 0.249683 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 43 train_time: 0.002999 loss: 0.363037 val_time: 0.000000 val_loss: 0.248684 acc_train: 0.825000 acc_val: 0.850000\n",
      "epoch 44 train_time: 0.002522 loss: 0.362824 val_time: 0.002007 val_loss: 0.247741 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 45 train_time: 0.003505 loss: 0.362652 val_time: 0.001505 val_loss: 0.246838 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 46 train_time: 0.004003 loss: 0.362324 val_time: 0.001511 val_loss: 0.246010 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 47 train_time: 0.003512 loss: 0.362041 val_time: 0.001003 val_loss: 0.245197 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 48 train_time: 0.004516 loss: 0.361953 val_time: 0.001004 val_loss: 0.244408 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 49 train_time: 0.004000 loss: 0.361793 val_time: 0.000504 val_loss: 0.243638 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 50 train_time: 0.002003 loss: 0.361834 val_time: 0.001001 val_loss: 0.242950 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 51 train_time: 0.002507 loss: 0.361984 val_time: 0.001509 val_loss: 0.242281 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 52 train_time: 0.004003 loss: 0.361210 val_time: 0.001000 val_loss: 0.241584 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 53 train_time: 0.004012 loss: 0.361681 val_time: 0.001000 val_loss: 0.240972 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 54 train_time: 0.002576 loss: 0.361473 val_time: 0.000932 val_loss: 0.240368 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 55 train_time: 0.004011 loss: 0.361074 val_time: 0.000000 val_loss: 0.239780 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 56 train_time: 0.003521 loss: 0.360974 val_time: 0.001004 val_loss: 0.239172 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 57 train_time: 0.003506 loss: 0.361096 val_time: 0.001006 val_loss: 0.238614 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 58 train_time: 0.003176 loss: 0.360911 val_time: 0.001024 val_loss: 0.238070 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 59 train_time: 0.003010 loss: 0.360845 val_time: 0.000000 val_loss: 0.237583 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 60 train_time: 0.002999 loss: 0.360884 val_time: 0.000000 val_loss: 0.237081 acc_train: 0.837500 acc_val: 0.850000\n",
      "epoch 61 train_time: 0.003015 loss: 0.360581 val_time: 0.001006 val_loss: 0.236579 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 62 train_time: 0.003025 loss: 0.360600 val_time: 0.000527 val_loss: 0.236103 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 63 train_time: 0.003328 loss: 0.360341 val_time: 0.000000 val_loss: 0.235676 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 64 train_time: 0.003003 loss: 0.360319 val_time: 0.001004 val_loss: 0.235251 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 65 train_time: 0.003001 loss: 0.360545 val_time: 0.000000 val_loss: 0.234822 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 66 train_time: 0.003535 loss: 0.360842 val_time: 0.001003 val_loss: 0.234394 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 67 train_time: 0.003495 loss: 0.360977 val_time: 0.000508 val_loss: 0.234037 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 68 train_time: 0.002999 loss: 0.360346 val_time: 0.001000 val_loss: 0.233651 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 69 train_time: 0.003518 loss: 0.359978 val_time: 0.000999 val_loss: 0.233288 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 70 train_time: 0.004214 loss: 0.360159 val_time: 0.000000 val_loss: 0.232953 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 71 train_time: 0.003001 loss: 0.360570 val_time: 0.001577 val_loss: 0.232614 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 72 train_time: 0.003012 loss: 0.360123 val_time: 0.001002 val_loss: 0.232295 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 73 train_time: 0.003073 loss: 0.360036 val_time: 0.000948 val_loss: 0.232000 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 74 train_time: 0.003015 loss: 0.359961 val_time: 0.000999 val_loss: 0.231679 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 75 train_time: 0.003037 loss: 0.360137 val_time: 0.001031 val_loss: 0.231392 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 76 train_time: 0.004022 loss: 0.360106 val_time: 0.000534 val_loss: 0.231085 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 77 train_time: 0.003093 loss: 0.359958 val_time: 0.001007 val_loss: 0.230827 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 78 train_time: 0.003040 loss: 0.360129 val_time: 0.001015 val_loss: 0.230591 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 79 train_time: 0.003000 loss: 0.359886 val_time: 0.000000 val_loss: 0.230347 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 80 train_time: 0.003521 loss: 0.359734 val_time: 0.000993 val_loss: 0.230123 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 81 train_time: 0.003508 loss: 0.359866 val_time: 0.000503 val_loss: 0.229876 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 82 train_time: 0.003001 loss: 0.359656 val_time: 0.001000 val_loss: 0.229642 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 83 train_time: 0.003667 loss: 0.359801 val_time: 0.000998 val_loss: 0.229397 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 84 train_time: 0.002506 loss: 0.359847 val_time: 0.001009 val_loss: 0.229189 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 85 train_time: 0.003010 loss: 0.359874 val_time: 0.000999 val_loss: 0.228981 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 86 train_time: 0.003508 loss: 0.360050 val_time: 0.000503 val_loss: 0.228757 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 87 train_time: 0.003998 loss: 0.359650 val_time: 0.000000 val_loss: 0.228574 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 88 train_time: 0.003511 loss: 0.360080 val_time: 0.000998 val_loss: 0.228386 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 89 train_time: 0.003997 loss: 0.359686 val_time: 0.001510 val_loss: 0.228195 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 90 train_time: 0.003000 loss: 0.359834 val_time: 0.001586 val_loss: 0.228029 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 91 train_time: 0.003245 loss: 0.360455 val_time: 0.001001 val_loss: 0.227878 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 92 train_time: 0.003034 loss: 0.359624 val_time: 0.001028 val_loss: 0.227697 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 93 train_time: 0.003077 loss: 0.359560 val_time: 0.000000 val_loss: 0.227537 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 94 train_time: 0.004198 loss: 0.359635 val_time: 0.000507 val_loss: 0.227367 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 95 train_time: 0.003508 loss: 0.360134 val_time: 0.000929 val_loss: 0.227202 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 96 train_time: 0.004000 loss: 0.359662 val_time: 0.001001 val_loss: 0.227049 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 97 train_time: 0.003509 loss: 0.359658 val_time: 0.001000 val_loss: 0.226909 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 98 train_time: 0.002505 loss: 0.359893 val_time: 0.001510 val_loss: 0.226755 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 99 train_time: 0.003000 loss: 0.359482 val_time: 0.001000 val_loss: 0.226619 acc_train: 0.850000 acc_val: 0.850000\n",
      "epoch 100 train_time: 0.004114 loss: 0.359584 val_time: 0.000971 val_loss: 0.226498 acc_train: 0.850000 acc_val: 0.850000\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
    "\n",
    "original_model = LoR()\n",
    "model = LoRModel(model=original_model, loss_fn=BCEWithLogitsLoss(),\n",
    "                 optimizer=SGD(original_model.parameters(), lr = 0.1))\n",
    "\n",
    "model.train(train_loader, val_loader, epoch_num=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2221e114e00>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.stats['losses'])\n",
    "plt.plot(model.stats['val_losses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
