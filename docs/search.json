[
  {
    "objectID": "contents/1/intro.html#what-is-machine-learning",
    "href": "contents/1/intro.html#what-is-machine-learning",
    "title": "1  Introduction",
    "section": "1.1 What is Machine Learning?",
    "text": "1.1 What is Machine Learning?\nMachine Learning is the science (and art) of programming computers so they can learn from data [1].\nHere is a slightly more general definition:\n\n[Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed.\n                                                   -- Arthur Samuel, 1959\n\nThis “without being explicitly programmed to do so” is the essential difference between Machine Learning and usual computing tasks. The usual way to make a computer do useful work is to have a human programmer write down rules — a computer program — to be followed to turn input data into appropriate answers. Machine Learning turns this around: the machine looks at the input data and the expected task outcome, and figures out what the rules should be. A Machine Learning system is trained rather than explicitly programmed. It’s presented with many examples relevant to a task, and it finds statistical structure in these examples that eventually allows the system to come up with rules for automating the task [2].",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "contents/1/intro.html#types-of-machine-learning-systems",
    "href": "contents/1/intro.html#types-of-machine-learning-systems",
    "title": "1  Introduction",
    "section": "1.2 Types of Machine Learning Systems",
    "text": "1.2 Types of Machine Learning Systems\nThere are many different types of Machine Learning systems that it is useful to classify them in braod categories, based on different criteria. These criteria are not exclusive, and you can combine them in any way you like.\nThe most popular criterion for Machine Learning classification is the amount and type of supervision they get during training. In this case there are four major types.\nSupervised Learning The training set you feed to the algorithm includes the desired solutions. The machines learn from the data to alter the model to get the desired output. The main task for Supervised Learning is classification and regression.\nUnsupervised Learning In Unsupervised Learning, the data provided doesn’t have class information or desired solutions. We just want to dig some information directly from those data themselves. Usually Unsupervised Learning is used for clustering and dimension reduction.\nReinforcement Learning In Reinforcement Learning, there is a reward system to measure how well the machine performs the task, and the machine is learning to find the strategy to maximize the rewards. Typical examples here include gaming AI and walking robots.\nSemisupervised Learning This is actually a combination of Supervised Learning and Unsupervised Learning, that it is usually used to deal with data that are half labelled.\n\n1.2.1 Tasks for Supervised Learning\nAs mentioned above, for Supervised Learning, there are two typical types of tasks:\nClassification It is the task of predicting a discrete class labels. A typical classification problem is to see an handwritten digit image and recognize it.\nRegression It is the task of predicting a continuous quantity. A typical regression problem is to predict the house price based on various features of the house.\nThere are a lot of other tasks that are not directly covered by these two, but these two are the most classical Supervised Learning tasks.\n\n\n\n\n\n\nNote\n\n\n\nIn this course we will mainly focus on Supervised Classification problems.\n\n\n\n\n1.2.2 Classification based on complexity\nAlong with the popularity boost of deep neural network, there comes another classificaiton: shallow learning vs. deep learning. Basically all but deep neural network belongs to shallow learning. Although deep learning can do a lot of fancy stuffs, shallow learning is still very good in many cases. When the performance of a shallow learning model is good enough comparing to that of a deep learning model, people tend to use the shallow learning since it is usually faster, easier to understand and easier to modify.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "contents/1/intro.html#basic-setting-for-machine-learning-problems",
    "href": "contents/1/intro.html#basic-setting-for-machine-learning-problems",
    "title": "1  Introduction",
    "section": "1.3 Basic setting for Machine learning problems",
    "text": "1.3 Basic setting for Machine learning problems\n\n\n\n\n\n\nNote\n\n\n\nWe by default assume that we are dealing with a Supervised Classification problem.\n\n\n\n1.3.1 Input and output data structure\nSince we are dealing with Supervised Classification problems, the desired solutions are given. These desired solutions in Classification problems are also called labels. The properties that the data are used to describe are called features. Both features and labels are usually organized as row vectors.\n\nExample 1.1 The example is extracted from [3]. There are some sample data shown in the following table. We would like to use these information to classify bird species.\n\n\n\n\nTable 1.1: Bird species classification based on four features\n\n\n\n\n\n\n\n\nWeight (g)\nWingspan (cm)\nWebbed feet?\nBack color\nSpecies\n\n\n\n\n1000.100000\n125.000000\nNo\nBrown\nButeo jamaicensis\n\n\n3000.700000\n200.000000\nNo\nGray\nSagittarius serpentarius\n\n\n3300.000000\n220.300000\nNo\nGray\nSagittarius serpentarius\n\n\n4100.000000\n136.000000\nYes\nBlack\nGavia immer\n\n\n3.000000\n11.000000\nNo\nGreen\nCalothorax lucifer\n\n\n570.000000\n75.000000\nNo\nBlack\nCampephilus principalis\n\n\n\n\n\n\n\n\nThe first four columns are features, and the last column is the label. The first two features are numeric and can take on decimal values. The third feature is binary that can only be \\(1\\) (Yes) or \\(0\\) (No). The fourth feature is an enumeration over the color palette. You may either treat it as categorical data or numeric data, depending on how you want to build the model and what you want to get out of the data. In this example we will use it as categorical data that we only choose it from a list of colors (\\(1\\) — Brown, \\(2\\) — Gray, \\(3\\) — Black, \\(4\\) — Green).\nThen we are able to transform the above data into the following form:\n\n\n\nTable 1.2: Vectorized Bird species data\n\n\n\n\n\nFeatures\nLabels\n\n\n\n\n\\(\\begin{bmatrix}1001.1 & 125.0 & 0 & 1 \\end{bmatrix}\\)\n\\(1\\)\n\n\n\\(\\begin{bmatrix}3000.7 & 200.0 & 0 & 2 \\end{bmatrix}\\)\n\\(2\\)\n\n\n\\(\\begin{bmatrix}3300.0 & 220.3 & 0 & 2 \\end{bmatrix}\\)\n\\(2\\)\n\n\n\\(\\begin{bmatrix}4100.0 & 136.0 & 1 & 3 \\end{bmatrix}\\)\n\\(3\\)\n\n\n\\(\\begin{bmatrix}3.0 & 11.0 & 0 & 4 \\end{bmatrix}\\)\n\\(4\\)\n\n\n\\(\\begin{bmatrix}570.0 & 75.0 & 0 & 3 \\end{bmatrix}\\)\n\\(5\\)\n\n\n\n\n\n\nThen the Supervised Learning problem is stated as follows: Given the features and the labels, we would like to find a model that can classify future data.\n\n\n\n1.3.2 Parameters and hyperparameters\nA model parameter is internal to the model and its value is learned from the data.\nA model hyperparameter is external to the model and its value is set by people.\nFor example, assume that we would like to use Logistic regression to fit the data. We set the learning rate is 0.1 and the maximal iteration is 100. After the computations are done, we get a the model\n\\[\ny = \\sigma(0.8+0.7x).\n\\] The two cofficients \\(0.8\\) and \\(0.7\\) are the parameters of the model. The model Logistic regression, the learning rate 0.1 and the maximal iteration 100 are all hyperparametrs. If we change to a different set of hyperparameters, we may get a different model, with a different set of parameters.\nThe details of Logistic regression will be discussed later.\n\n\n1.3.3 Evaluate a Machine Learning model\nOnce the model is built, how do we know that it is good or not? The naive idea is to test the model on some brand new data and check whether it is able to get the desired results. The usual way to achieve it is to split the input dataset into three pieces: training set, validation set and test set.\nThe model is initially fit on the training set, with some arbitrary selections of hyperparameters. Then hyperparameters will be changed, and new model is fitted over the training set. Which set of hyperparameters is better? We then test their performance over the validation set. We could run through a lot of different combinations of hyperparameters, and find the best performance over the validation set. After we get the best hyperparameters, the model is selcted, and we fit it over the training set to get our model to use.\nTo compare our model with our models, either our own model using other algorithms, or models built by others, we need some new data. We can no longer use the training set and the validation set since all data in them are used, either for training or for hyperparameters tuning. We need to use the test set to evaluate the “real performance” of our data.\nTo summarize:\n\nTraining set: used to fit the model;\nValidation set: used to tune the hyperparameters;\nTest set: used to check the overall performance of the model.\n\nThe validation set is not always required. If we use cross-validation technique for hyperparameters tuning, like sklearn.model_selection.GridSearchCV(), we don’t need a separated validation set. In this case, we will only need the training set and the test set, and run GridSearchCV over the training set. The cross-validation will be discussed in {numref}Section %s&lt;section-cross-validation&gt;.\nThe sizes and strategies for dataset division depends on the problem and data available. It is often recommanded that more training data should be used. The typical distribution of training, validation and test is \\((6:3:1)\\), \\((7:2:1)\\) or \\((8:1:1)\\). Sometimes validation set is discarded and only training set and test set are used. In this case the distribution of training and test set is usually \\((7:3)\\), \\((8:2)\\) or \\((9:1)\\).\n\n\n1.3.4 Workflow in developing a machine learning application\nThe workflow described below is from [3].\n\nCollect data.\nPrepare the input data.\nAnalyze the input data.\nTrain the algorithm.\nTest the algorithm.\nUse it.\n\nIn this course, we will mainly focus on Step 4 as well Step 5. These two steps are where the “core” algorithms lie, depending on the algorithm. We will start from the next Chapter to talk about various Machine Learning algorithms and examples.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "contents/1/intro.html#python-quick-guide",
    "href": "contents/1/intro.html#python-quick-guide",
    "title": "1  Introduction",
    "section": "1.4 Python quick guide",
    "text": "1.4 Python quick guide\n\n1.4.1 Python Notebook\nWe mainly use Python Notebook (.ipynb) to write documents for this course. Currently all main stream Python IDE support Python Notebook. All of them are not entirely identical but the differences are not huge and you may choose any you like.\nOne of the easiest ways to use Python Notebook is through JupyterLab. The best part about it is that you don’t need to worry about installation and configuration in the first place, and you can directly start to code.\nClick the above link and choose JupyterLab. Then you will see the following page.\n\nThe webapp you just started is called JupyterLite. This is a demo version. The full JupyterLab installation instruction can also be found from the link.\nThere is a small button + under the tab bar. This is the place where you click to start a new cell. You may type codes or markdown documents or raw texts in the cell according to your needs. The drag-down menu at the end of the row which is named Code or Markdown or Raw can help you make the switch. Markdown is a very simple light wighted language to write documents. In most cases it behaves very similar to plain texts. Codes are just regular Python codes (while some other languages are supported). You may either use the triangle button in the menu to execute the codes, or hit shift + enter.\n\nJupyterLite contains a few popular packages. Therefore it is totally ok if you would like to play with some simple things. However since it is an online evironment, it has many limitations. Therefore it is still recommended to set up a local environment once you get familiar with Python Notebook. Please check the following links for some popular choices for notebooks and Python installations in general, either local and online.\n\nJupyter Notebook / JupyterLab\nVS Code\nPyCharm\nGoogle Colab\nAnaconda\n\n\n\n1.4.2 Python fundamentals\nWe will put some very basic Python commands here for you to warm up. More advanced Python knowledge will be covered during the rest of the semester. The main reference for this part is [3]. Another referenece is My notes.\n\n1.4.2.1 Indentation\nPython is using indentation to denote code blocks. It is not convienent to write in the first place, but it forces you to write clean, readable code.\nBy the way, the if and for block are actually straightforward.\nif jj &lt; 3:\n    jj = jj \n    print(\"It is smaller than 3.\")\nif jj &lt; 3:\n    jj = jj\nprint(\"It is smaller than 3.\")\nfor i in range(3):\n    i = i + 1\n    print(i)\nfor i in range(3):\n    i = i + 1\nprint(i)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlease tell the differences between the above codes.\n\n\n1.4.2.2 list and dict\nHere are some very basic usage of lists of dictionaries in Python.\n\nnewlist = list()\nnewlist.append(1)\nnewlist.append('hello')\nnewlist\n\n[1, 'hello']\n\n\n\nnewlisttwo = [1, 'hello']\nnewlisttwo\n\n[1, 'hello']\n\n\n\nnewdict = dict()\nnewdict['one'] = 'good'\nnewdict[1] = 'yes'\nnewdict\n\n{'one': 'good', 1: 'yes'}\n\n\n\nnewdicttwo = {'one': 'good', 1: 'yes'}\nnewdicttwo\n\n{'one': 'good', 1: 'yes'}\n\n\n\n\n1.4.2.3 Loop through lists\nWhen creating for loops we may let Python directly loop through lists. Here is an example. The code is almost self-explained.\n\nalist = ['one', 2, 'three', 4]\n\nfor item in alist:\n    print(item)\n\none\n2\nthree\n4\n\n\n\n\n1.4.2.4 Reading files\nThere are a lot of functions that can read files. The basic one is to read any files as a big string. After we get the string, we may parse it based on the structure of the data.\nThe above process sounds complicated. That’s why we have so many different functions reading files. Usually they focus on a certain types of files (e.g. spreadsheets, images, etc..), parse the data into a particular data structure for us to use later.\nI will mention a few examples.\n\ncsv files and excel files Both of them are spreadsheets format. Usually we use pandas.read_csv and pandas.read_excel both of which are from the package pandas to read these two types of files.\nimages Images can be treated as matrices, that each entry represents one pixel. If the image is black/white, it is represented by one matrix where each entry represents the gray value. If the image is colored, it is represented by three matrices where each entry represents one color. To use which three colors depends on the color map. rgb is a popular choice.\nIn this course when we need to read images, we usually use matplotlib.pyplot.imread from the package matplotlib or cv.imread from the package opencv.\n.json files .json is a file format to store dictionary type of data. To read a json file and parse it as a dictionary, we need json.load from the package json.\n\n\n\n1.4.2.5 Writing files\n\npandas.DataFrame.to_csv\npandas.DataFrame.to_excel\nmatplotlib.pyplot.imsave\ncv.imwrite\njson.dump\n\n\n\n1.4.2.6 Relative paths\nIn this course, when reading and writing files, please keep all the files using relative paths. That is, only write the path starting from the working directory.\n\nExample 1.2 Consider the following tasks:\n\nYour working directory is C:/Users/Xinli/projects/.\nWant to read a file D:/Files/example.csv.\nWant to generate a file whose name is result.csv and put it in a subfoler named foldername.\n\nTo do the tasks, don’t directly run the code pd.read_csv('D:/Files/example.csv'). Instead you should first copy the file to your working directory C:/Users/Xinli/projects/, and then run the following code.\n\nimport pandas as pd\n\ndf = pd.read_csv('example.csv')\ndf.to_csv('foldername/result.csv')\n\nPlease pay attention to how the paths are written.\n\n\n\n1.4.2.7 .\n\nclass and packages.\nGet access to attributes and methods\nChaining dots.\n\n\n\n\n1.4.3 Some additional topics\nYou may read about these parts from the appendices of My notes.\n\n1.4.3.1 Package management and Virtual environment\n\nconda\n\nconda create\n\nconda create --name myenv\nconda create --name myenv python=3.9\nconda create --name myenv --file spec-file.txt\n\nconda install\n\nconda install -c conda-forge numpy\n\nconda activate myenv\nconda list\n\nconda list numpy\nconda list --explicit &gt; spec-file.txt\n\nconda env list\n\npip / venv\n\npython -m venv newenv\nnewenv\\Scripts\\activate\npip install\npip freeze &gt; requirements.txt\npip install -r /path/to/requirements.txt\ndeactivate\n\n\n\n\n1.4.3.2 Version Control\n\nGit\n\nInstall\ngit config --list\ngit config --global user.name \"My Name\"\ngit config --global user.email \"myemail@example.com\"\n\nGitHub",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "contents/1/intro.html#exercises",
    "href": "contents/1/intro.html#exercises",
    "title": "1  Introduction",
    "section": "1.5 Exercises",
    "text": "1.5 Exercises\nThese exercises are from [4], [1] and [3].\n\n1.5.1 Python Notebook\n\nExercise 1.1 (Hello World!) Please set up a Python Notebook environment and type print('Hello World!').\n\n\nExercise 1.2 Please set up a Python Notebook and start a new virtual environment and type print('Hello World!').\n\n\n\n1.5.2 Basic Python\n\nExercise 1.3 (Play with lists) Please complete the following tasks.\n\nWrite a for loop to print values from 0 to 4.\nCombine two lists ['apple', 'orange'] and ['banana'] using +.\nSort the list ['apple', 'orange', 'banana'] using sorted().\n\n\n\n\nExercise 1.4 (Play with list, dict and pandas.) Please complete the following tasks.\n\nCreate a new dictionary people with two keys name and age. The values are all empty list.\nAdd Tony to the name list in people.\nAdd Harry to the name list in people.\nAdd number 100 to the age list in people.\nAdd number 10 to the age list in people.\nFind all the keys of people and save them into a list namelist.\nConvert the dictionary people to a Pandas DataFrame df.\n\n\n\n\nExercise 1.5 (The dataset iris)  \n\nfrom sklearn.datasets import load_iris\niris = load_iris()\n\nPlease explore this dataset.\n\nPlease get the features for iris and save it into X as an numpy array.\nWhat is the meaning of these features?\nPlease get the labels for iris and save it into y as an numpy array.\nWhat is the meaning of labels?\n\n\n\n\nExercise 1.6 (Play with Pandas) Please download the Titanic data file from here. Then follow the instructions to perform the required tasks.\n\nUse pandas.read_csv to read the dataset and save it as a dataframe object df.\nChange the values of the Sex column that male is 0 and female is 1.\nPick the columns Pclass, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard and Fare and transform them into a 2-dimensional numpy.ndarray, and save it as X.\nPick the column Survived and transform it into a 1-dimensional numpy.ndarray and save it as y.\n\n\n\n\n\n\n\n[1] Géron, A. (2019). Hands-on machine learning with scikit-learn, keras, and TensorFlow concepts, tools, and techniques to build intelligent systems: Concepts, tools, and techniques to build intelligent systems. O’Reilly Media.\n\n\n[2] Chollet, F. (2021). Deep learning with python, second edition. MANNING PUBN.\n\n\n[3] Harrington, P. (2012). Machine learning in action. Manning Publications.\n\n\n[4] Klosterman, S. (2021). Data science projects with python: A case study approach to gaining valuable insights from real data with machine learning. Packt Publishing, Limited.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "contents/5/intro.html#basic-idea",
    "href": "contents/5/intro.html#basic-idea",
    "title": "5  Logistic regression",
    "section": "5.1 Basic idea",
    "text": "5.1 Basic idea\nThe Logsitic regression is used to predict the probability of a data point belonging to a specific class. It is based on linear regression. The major difference is that logistic regreesion will have an activation function \\(\\sigma\\) at the final stage to change the predicted values of the linear regression to the values that indicate classes. In the case of binary classification, the outcome of \\(\\sigma\\) will be between \\(0\\) and \\(1\\), which is related to the two classes respectively. In this case, the number is interepted as the probability of the data to be in one of the specific class.\nThe model for Logistic regression is as follows:\n\\[\np=\\sigma(L(x))=\\sigma\\left(\\theta_0+\\sum_{j=1}^n\\theta_jx_j\\right)=\\sigma\\left(\\Theta \\hat{x}^T\\right).\n\\]\nIn most cases, this activation function is chosen to be the Sigmoid funciton.\n\n5.1.1 Sigmoid function\nThe Sigmoid function is defined as follows:\n\\[\n\\sigma(z)=\\frac{1}{1+\\mathrm{e}^{-z}}.\n\\] The graph of the function is shown below.\n\n\n\n\n\n\n\n\n\nThe main properties of \\(\\sigma\\) are listed below as a Lemma.\n\nLemma 5.1 The Sigmoid function \\(\\sigma(z)\\) satisfies the following properties.\n\n\\(\\sigma(z)\\rightarrow \\infty\\) when \\(z\\mapsto \\infty\\).\n\\(\\sigma(z)\\rightarrow -\\infty\\) when \\(z\\mapsto -\\infty\\).\n\\(\\sigma(0)=0.5\\).\n\\(\\sigma(z)\\) is always increasing.\n\\(\\sigma'(z)=\\sigma(z)(1-\\sigma(z))\\).\n\n\n\nSolution. We will only look at the last one.\n\\[\n\\begin{split}\n\\sigma'(z)&=-\\frac{(1+\\mathrm e^{-z})'}{(1+\\mathrm e^{-z})^2}=\\frac{\\mathrm e^{-z}}{(1+\\mathrm e^{-z})^2}=\\frac{1}{1+\\mathrm e^{-z}}\\frac{\\mathrm e^{-z}}{1+\\mathrm e^{-z}}\\\\\n&=\\sigma(z)\\left(\\frac{1+\\mathrm e^{-z}}{1+\\mathrm e^{-z}}-\\frac{1}{1+\\mathrm e^{-z}}\\right)=\\sigma(z)(1-\\sigma(z)).\n\\end{split}\n\\]\n\n\n\n5.1.2 Gradient descent\nAssume that we would like to minimize a function \\(J(\\Theta)\\), where this \\(\\Theta\\) is an \\(N\\)-dim vector. Geometricly, we could treat \\(J\\) as a height function, and it tells us the height of the mountain. Then to minimize \\(J\\) is the same thing as to find the lowest point. One idea is to move towards the lowest point step by step. During each step we only need to lower our current height. After several steps we will be around the lowest point.\nThe geometric meaning of \\(\\nabla J\\) is the direction that \\(J\\) increase the most. Therefore the opposite direction is the one we want to move in. The formula to update \\(x\\) is\n\\[\n\\Theta_{\\text{new}} = \\Theta_{\\text{old}}-\\alpha \\nabla J(\\Theta_{\\text{old}}),\n\\] where \\(\\alpha\\) is called the learning rate which controls how fast you want to learn. Usually if \\(\\alpha\\) is small, the learning tends to be slow and stble, and when \\(\\alpha\\) is big, the learning tends to be fast and unstable.\nIn machine learning, in most cases we would like to formulate the problem in terms of finding the lowest point of a cost function \\(J(\\Theta)\\). Then we could start to use Logistic regression to solve it. For binary classification problem, the cost function is defined to be\n\\[\nJ(\\Theta)=-\\frac1m\\sum_{i=1}^m\\left[y^{(i)}\\log(p^{(i)})+(1-y^{(i)})\\log(1-p^{(i)})\\right].\n\\] Here \\(m\\) is the number of data points, \\(y^{(i)}\\) is the labelled result (which is either \\(0\\) or \\(1\\)), \\(p^{(i)}\\) is the predicted value (which is between \\(0\\) and \\(1\\)).\n\n\n\n\n\n\nNote\n\n\n\nThe algorithm gets its name since we are using the gradient to find a direction to lower our height.\n\n\n\n\n5.1.3 The Formulas\n\nTheorem 5.1 The gradient of \\(J\\) is computed by\n\\[\n\\nabla J =\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}.\n\\tag{5.1}\\]\n\n\n\nClick for details.\n\n\nProof. The formula is an application of the chain rule for the multivariable functions.\n\\[\n\\begin{split}\n\\dfrac{\\partial p}{\\partial \\theta_k}&=\\dfrac{\\partial}{\\partial \\theta_k}\\sigma\\left(\\theta_0+\\sum_{j=1}^n\\theta_jx_j\\right)=\\dfrac{\\partial}{\\partial \\theta_k}\\sigma(L(\\Theta))\\\\\n&=\\sigma(L)(1-\\sigma(L))\\dfrac{\\partial}{\\partial \\theta_k}\\left(\\theta_0+\\sum_{j=1}^n\\theta_jx_j\\right)\\\\\n&=\\begin{cases}\np(1-p)&\\text{ if }k=0,\\\\\np(1-p)x_k&\\text{ otherwise}.\n\\end{cases}\n\\end{split}\n\\] Then\n\\[\n\\nabla p = \\left(\\frac{\\partial p}{\\partial\\theta_0},\\ldots,\\frac{\\partial p}{\\partial\\theta_n}\\right) = p(1-p)\\hat{x}.\n\\]\nThen\n\\[\n\\nabla \\log(p) = \\frac{\\nabla p}p =\\frac{p(1-p)\\hat{x}}{p}=(1-p)\\hat{x}.\n\\]\n\\[\n\\nabla \\log(1-p) = \\frac{-\\nabla p}{1-p} =-\\frac{p(1-p)\\hat{x}}{1-p}=-p\\hat{x}.\n\\]\nThen\n\\[\n\\begin{split}\n\\nabla J& = -\\frac1m\\sum_{i=1}^m\\left[y^{(i)}\\nabla \\log(p^{(i)})+(1-y^{(i)})\\nabla \\log(1-p^{(i)})\\right]\\\\\n&=-\\frac1m\\sum_{i=1}^m\\left[y^{(i)}(1-p^{(i)})\\hat{x}^{(i)}+(1-y^{(i)})(-p^{(i)}\\hat{x}^{(i)})\\right]\\\\\n&=-\\frac1m\\sum_{i=1}^m\\left[(y^{(i)}-p^{(i)})\\hat{x}^{(i)}\\right].\n\\end{split}\n\\]\nWe write \\(\\hat{x}^{(i)}\\) as row vectors, and stack all these row vectors vertically. What we get is a matrix \\(\\hat{\\textbf X}\\) of the size \\(m\\times (1+n)\\). We stack all \\(y^{(i)}\\) (resp. \\(p^{(i)}\\)) vectically to get the \\(m\\)-dim column vector \\(\\textbf y\\) (resp. \\(\\textbf p\\)).\nUsing this notation, the previous formula becomes\n\\[\n\\nabla J =\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}.\n\\]\nAfter the gradient can be computed, we can start to use the gradient descent method. Note that, although \\(\\Theta\\) are not explicitly presented in the formula of \\(\\nabla J\\), this is used to modify \\(\\Theta\\):\n\\[\n\\Theta_{s+1} = \\Theta_s - \\alpha\\nabla J.\n\\]\n\n\n\n\n5.1.4 Codes\nWe will only talk about using packages. sklearn provides two methods to implement the Logistic regression. The API interface is very similar to other models.\nNote that Logistic regression is very sensitive to the scale of features. Therefore we need to normalize the features before throwing them into the model.\nLet’s still take iris as an example.\n\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\n\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n\nThe first method is sklearn.linear_model.LogisticRegression.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\nsteps = [('normalize', MinMaxScaler()),\n         ('log', LogisticRegression())]\n\nlog_reg = Pipeline(steps=steps)\nlog_reg.fit(X_train, y_train)\nlog_reg.score(X_test, y_test)\n\n0.9565217391304348\n\n\nNote that this method has an option solver that will set the way to solve the Logistic regression problem, and there is no “stochastic gradient descent” provided. The default solver for this LogsiticRegression is lbfgs which will NOT be discussed in lectures.\nThe second method is sklearn.linear_model.SGDClassifier.\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\nsteps = [('normalize', MinMaxScaler()),\n         ('log', SGDClassifier(loss='log_loss', max_iter=100))]\n\nsgd_clf = Pipeline(steps=steps)\nsgd_clf.fit(X_train, y_train)\nsgd_clf.score(X_test, y_test)\n\n0.782608695652174\n\n\nThis method is the one we discussed in lectures. The log_loss loss function is the binary entropy function we mentioned in lectures. If you change to other loss functions it will become other models.\nFrom the above example, you may notice that SGDClassifier doesn’t perform as well as LogisticRegression. This is due to the algorithm. To make SGDClassifier better you need to tune the hyperparameters, like max_iter, learning_rate/alpha, penalty, etc..\n\n\n\n\n\n\nNote\n\n\n\nThe argument warm_start is used to set whether you want to use your previous model. When set to True, it will reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. The default is False.\nRepeatedly calling fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled.\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that for both methods, regularization (which will be discussed later) is applied by default.\n\n\n\n\n5.1.5 Several important side topics\n\n5.1.5.1 Epochs\nWe use epoch to describe feeding data into the model. One Epoch is when an entire dataset is passed through the model once. When using gradient descent, we tend to run several epochs. The number of maximal epochs is one important hyperparameter of this model.\nThe general idea is that more epochs are better for the score of the model, but it will definitely be slower. In addition, sometimes due to many other factors, after a few epochs, the model becomes stall. To train for more epochs cannot improve the model. In this case you have to turn to other methods.\n\n\n5.1.5.2 Batch Gradient Descent vs SGD vs Minibatch\nRecall the Formula Equation 5.1:\n\\[\n\\nabla J =\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}.\n\\] We could rewrite this formula:\n\\[\n\\nabla J =\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}=\\frac1m\\sum_{i=1}^m\\left[(p^{(i)}-y^{(i)})\\hat{x}^{(i)}\\right].\n\\] This new formula can be understood in the following way: For every data point, we could get one gradient direction. Then \\(\\nabla J\\) is the average of all gradient directions. So this algorithm can be expressed as that compute the gradient for every data points and then take the average, and finally update the parameters once. This algorithm is called batch gradient descent.\nFollowing the idea, there is another way to update the model. For every data point, we could compute one gradient direction, and we could use the gradient direction to update the parameters of the model. This algorithm is called stochastic gradient descent.\nThen there is an algrothm living in the middle, called mini-batch gradient descent. In this case, we will group the data set into a collection of subsets of a fiexed number of training examples. Each subset is called a mini-batch, and the fixed number of elements of each mini-batch is called the batch size. Using this method, we will just go through mini-batches one at a time, compute the average of the gradient for these data, and then update the parameters of the model after we finish one mini-batch. Assume that the total number of the dataset is N, the mini-batch size is m. Then there are N/m mini-batches, and during one epoch we will update the model N/m times.\nMini-batch size is one important hyperparameters of this model. Usually the larger the batch size is, the less variance the model has. Then it tends to behave more smoothly, but it will also be slower, and might be stuck to a local minimal. The smaller batch size is more chaotic. It might go faster, but it tends not to converge.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "contents/5/intro.html#regularization",
    "href": "contents/5/intro.html#regularization",
    "title": "5  Logistic regression",
    "section": "5.2 Regularization",
    "text": "5.2 Regularization\n\n5.2.1 Three types of errors\nEvery estimator has its advantages and drawbacks. Its generalization error can be decomposed in terms of bias, variance and noise. The bias of an estimator is its average error for different training sets. The variance of an estimator indicates how sensitive it is to varying training sets. Noise is a property of the data.\n\n\n5.2.2 Underfit vs Overfit\nWhen fit a model to data, it is highly possible that the model is underfit or overfit.\nRoughly speaking, underfit means the model is not sufficient to fit the training samples, and overfit means that the models learns too many noise from the data. In many cases, high bias is related to underfit, and high variance is related to overfit.\nThe following example is from the sklearn guide. Although it is a polynomial regression example, it grasps the key idea of underfit and overfit.\n\n\n\n\n\n\n\n\n\n\n\n5.2.3 Learning curves (accuracy vs training size)\nA learning curve shows the validation and training score of an estimator for varying a key hyperparameter. In most cases the key hyperparameter is the training size or the number of epochs. It is a tool to find out how much we benefit from altering the hyperparameter by training more data or training for more epochs, and whether the estimator suffers more from a variance error or a bias error.\nsklearn provides sklearn.model_selection.learning_curve() to generate the values that are required to plot such a learning curve. However this function is just related to the sample size. If we would like to talk about epochs, we need other packages.\nLet us first look at the learning curve about sample size. The official document page is here. The function takes input estimator, dataset X, y, and an arry-like argument train_sizes. The dataset (X, y) will be split into pieces using the cross-validation technique. The number of pieces is set by the argument cv. The default value is cv=5. For details about cross-validation please see Section 2.2.6.\nThen the model is trained over a random sample of the training set, and evaluate the score over the test set. The size of the sample of the training set is set by the argument train_sizes. This argument is array-like. Therefore the process will be repeated several times, and we can see the impact of increasing the training size.\nThe output contains three pieces. The first is train_sizes_abs which is the number of elements in each training set. This output is mainly for reference. The difference between the output and the input train_sizes is that the input can be float which represents the percentagy. The output is always the exact number of elements.\nThe second output is train_scores and the third is test_scores, both of which are the scores we get from the training and testing process. Note that both are 2D numpy arrays, of the size (number of different sizes, cv). Each row is a 1D numpy array representing the cross-validation scores, which is corresponding to a train size. If we want the mean as the cross-validation score, we could use train_scores.mean(axis=1).\nAfter understanding the input and output, we could plot the learning curve. We still use the horse colic as the example. The details about the dataset can be found here.\n\nimport pandas as pd\nimport numpy as np\n\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data'\ndf = pd.read_csv(url, delim_whitespace=True, header=None)\ndf = df.replace(\"?\", np.NaN)\n\ndf.fillna(0, inplace=True)\ndf.drop(columns=[2, 24, 25, 26, 27], inplace=True)\ndf[23].replace({1: 1, 2: 0}, inplace=True)\nX = df.iloc[:, :-1].to_numpy().astype(float)\ny = df[23].to_numpy().astype(int)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\nWe use the model LogisticRegression. The following code plot the learning curve for this model.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\n\nclf = LogisticRegression(max_iter=1000)\nsteps = [('scalar', MinMaxScaler()),\n         ('log', clf)]\npipe = Pipeline(steps=steps)\nfrom sklearn.model_selection import learning_curve\nimport numpy as np\ntrain_sizes, train_scores, test_scores = learning_curve(pipe, X_train, y_train,\n                                                        train_sizes=np.linspace(0.1, 1, 20))\n\nimport matplotlib.pyplot as plt\nplt.plot(train_sizes, train_scores.mean(axis=1), label='train')\nplt.plot(train_sizes, test_scores.mean(axis=1), label='test')\nplt.legend()\n\n\n\n\n\n\n\n\nThe learning curve is a primary tool for us to study the bias and variance. Usually\n\nIf the two training curve and the testing curve are very close to each other, this means that the variance is low. Otherwise the variance is high, and this means that the model probabily suffer from overfitting.\nIf the absolute training curve score is high, this means that the bias is low. Otherwise the bias is high, and this means that the model probabily suffer from underfitting.\n\nIn the above example, although regularization is applied by default, you may still notice some overfitting there.\n\n\n5.2.4 Regularization\nRegularization is a technique to deal with overfitting. Here we only talk about the simplest method: ridge regression, also known as Tikhonov regularizaiton. Because of the formula given below, it is also called \\(L_2\\) regularization. The idea is to add an additional term \\(\\dfrac{\\alpha}{2m}\\sum_{i=1}^m\\theta_i^2\\) to the original cost function. When training with the new cost function, this additional term will force the parameters in the original term to be as small as possible. After finishing training, the additional term will be dropped, and we use the original cost function for validation and testing. Note that in the additional term \\(\\theta_0\\) is not presented.\nThe hyperparameter \\(\\alpha\\) is the regularization strength. If \\(\\alpha=0\\), the new cost function becomes the original one; If \\(\\alpha\\) is very large, the additional term dominates, and it will force all parameters to be almost \\(0\\). In different context, the regularization strength is also given by \\(C=\\dfrac{1}{2\\alpha}\\), called inverse of regularization strength.\n\n5.2.4.1 The math of regularization\n\nTheorem 5.2 The gradient of the ridge regression cost function is\n\\[\n\\nabla J=\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}+\\frac{\\alpha}{m}\\Theta.\n\\]\nNote that \\(\\Theta\\) doesn’t contain \\(\\theta_0\\), or you may treat \\(\\theta_0=0\\).\n\nThe computation is straightforward.\n\n\n5.2.4.2 The code\nRegularization is directly provided by the logistic regression functions.\n\nIn LogisticRegression, the regularization is given by the argument penalty and C. penalty specifies the regularizaiton method. It is l2 by default, which is the method above. C is the inverse of regularization strength, whose default value is 1.\nIn SGDClassifier, the regularization is given by the argument penalty and alpha. penalty is the same as that in LogisticRegression, and alpha is the regularization strength, whose default value is 0.0001.\n\nLet us see the above example.\n\nclf = LogisticRegression(max_iter=1000, C=0.1)\nsteps = [('scalar', MinMaxScaler()),\n         ('log', clf)]\npipe = Pipeline(steps=steps)\nfrom sklearn.model_selection import learning_curve\nimport numpy as np\ntrain_sizes, train_scores, test_scores = learning_curve(pipe, X_train, y_train,\n                                                        train_sizes=np.linspace(0.1, 1, 20))\n\nimport matplotlib.pyplot as plt\nplt.plot(train_sizes, train_scores.mean(axis=1), label='train')\nplt.plot(train_sizes, test_scores.mean(axis=1), label='test')\nplt.legend()\n\n\n\n\n\n\n\n\nAfter we reduce C from 1 to 0.1, the regularization strength is increased. Then you may find that the gap between the two curves are reduced. However the overall performace is also reduced, from 85%~90% in C=1 case to around 80% in C=0.1 case. This means that the model doesn’t fit the data well as the previous one. Therefore this is a trade-off: decrease the variance but increase the bias.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "contents/5/intro.html#neural-network-implement-of-logistic-regression",
    "href": "contents/5/intro.html#neural-network-implement-of-logistic-regression",
    "title": "5  Logistic regression",
    "section": "5.3 Neural network implement of Logistic regression",
    "text": "5.3 Neural network implement of Logistic regression\nIn the previous sections, we use gradient descent to run the Logistic regression model. We mentioned some important concepts, like epochs, mini-batch, etc.. But we didn’t implement them. In fact sklearn doesn’t provide a very good tool to do all these computations. Hence we turn to another package for this model. We are going to use keras to build a Logistic regression model, and plot the “loss vs epochs” learning curves.\nkeras is high level Neural network library. It is now in the phase of transition from single backend tensorflow to multi-backend. The old version is installed along with tensorflow. You may use the following command to install it.\npip install tensorflow\nIf you want to use new version, besides installing tensorflow, you should also install keras-core. Currently we still use tensorflow as the backend. This part may be updated after the stable version is released.\npip install keras-core\nYou may follow the instructions for tensforflow and keras for more details.\nTo use keras to implement logistic regression, we need the following modules: a Sequential model, a Dense layer. The model is organized as follows.\nWe still use the horse colic dataset as an example.\n\nimport pandas as pd\nimport numpy as np\n\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data'\ndf = pd.read_csv(url, delim_whitespace=True, header=None)\ndf = df.replace(\"?\", np.NaN)\n\ndf.fillna(0, inplace=True)\ndf.drop(columns=[2, 24, 25, 26, 27], inplace=True)\ndf[23].replace({1: 1, 2: 0}, inplace=True)\nX = df.iloc[:, :-1].to_numpy().astype(float)\ny = df[23].to_numpy().astype(int)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\nNote that we need to perform normalization before throwing the data into the model. Here we use the MinMaxScaler() from sklearn package. The normalization layer in keras is a little bit more complicated and doesn’t fit into situation.\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nmms = MinMaxScaler()\nmms.fit(X_train)\nX_train = mms.transform(X_train)\nX_test = mms.transform(X_test)\n\nIn the following code, we first set up the model, and then add one Dense layer. This Dense layer means that we would perform a linear transformation to the input, by the formula \\(\\theta_0+\\theta_1x_1+\\theta_2x_2+\\ldots+\\theta_nx_n\\). Then there are three arguments:\n\n1: means that there is only output.\nactivation='sigmoid': means that we will apply the sigmoid function after the linear transformation.\ninput_dim: means the dimension of the input. Note that this dimension is the dimension of one individual data point. You don’t take the size of the training set into consideration.\n\nAfter building the basic architectal of the model, we need to speicify a few more arguments. In the model.compile() step, we have to input the optimizer, the loss function (which is the binary_crossentropy in our case) and the metrics to test the performance of the model (which is accuracy in our case).\nThe optimizer is how the parameters are updated. The best choice in general is adam. The default setting is RMSprop and the optimizer discussed in our lecture is sgd. We will use adam here, since the learning curve it produces looks better (for illustration).\nFinally we could train the model. The argument is straightforward.\n\n# import keras_core as keras\nfrom keras import models, layers\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(1, activation='sigmoid', input_dim=X_train.shape[1]))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhist = model.fit(X_train, y_train, epochs=400, batch_size=30, validation_data=(X_test, y_test))\n\nNote that we assign the output of model.fit() to a variable hist. The infomation about this training process is recorded inside. We will extract those information.\n\nloss_train = hist.history['loss']\nloss_val = hist.history['val_loss']\n\nacc_train = hist.history['accuracy']\nacc_val = hist.history['val_accuracy']\n\nWe now could plot the learning curve (loss vs epochs) and the learning curve (accuracy vs epochs).\n\nimport matplotlib.pyplot as plt\nplt.plot(loss_train, label='train_loss')\nplt.plot(loss_val, label='val_loss')\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(acc_train, label='train_acc')\nplt.plot(acc_val, label='val_acc')\nplt.legend()\n\n\n\n\n\n\n\n\n\n5.3.1 Regularization\nTo apply regularization, we just need to modify the layer we added to the model. The argument is kernel_regularizer. We would like to set it to be keras.regularizers.L2(alpha), where alpha is the regularization strength.\n\nfrom keras import models, layers, regularizers\n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(1, activation='sigmoid', input_dim=X_train.shape[1],\n                       kernel_regularizer=regularizers.L2(0.5)))\n\nmodel.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\nhist = model.fit(X_train, y_train, epochs=400, batch_size=30,\n                 validation_data=(X_test, y_test))\n\n\nloss_train = hist.history['loss']\nloss_val = hist.history['val_loss']\n\nacc_train = hist.history['accuracy']\nacc_val = hist.history['val_accuracy']\n\nplt.plot(loss_train, label='train_loss')\nplt.plot(loss_val, label='val_loss')\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(acc_train, label='train_acc')\nplt.plot(acc_val, label='val_acc')\nplt.legend()\n\n\n\n\n\n\n\n\nYou may compare what we get here with the codes we get before.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "contents/5/intro.html#multi-class-case",
    "href": "contents/5/intro.html#multi-class-case",
    "title": "5  Logistic regression",
    "section": "5.4 Multi class case",
    "text": "5.4 Multi class case\n\n5.4.1 Naive idea (one-vs-all)\nAssume that there are \\(N\\) classes. The naive idea is to decompose this \\(N\\)-class classification problem into \\(N\\) binary classification problems. The model will contains \\(N\\) classifiers. The \\(i\\)th classifer is used to classify whehter the given features has the label i or not.\nFor example, asusme we are dealing with the iris dataset. There are 3 classes. By the naive idea, we will modify the labels into Setosa and not Setosa, and use it to train the first classifier. Similarly we can have two more classifiers to tell Versicolour/not Versicolour and Virginica/not Virginica. Then we combine all three classifiers to get a final classifier to put the data into one of the three classes.\n\n\n5.4.2 Softmax function\nA better method is mimic the sigmoid function. Recall that in binary classification problem, after\n\\[\nz=L(x)=\\theta_0+\\sum_{i=1}^n\\theta_ix_i,\n\\] the sigmoid function is applied \\(p=\\sigma(z)\\). This \\(p\\) is interepreted as the probability for the data belonging to class \\(1\\). For \\(N\\)-class problem, we could generalize the sigmoid function to softmax function, whose value is a \\(N\\)-dimensional vector \\(p=[p_k]_{i=1}^N\\). Here \\(p_k\\) represents the probability for the data belonging to class \\(k\\). Then after we get the vector \\(p\\), we then find the highest probability and that indicates the class of the data point.\nThe softmax function is defined in the following way:\n\\[\np_k=\\sigma(z)=\\dfrac{\\exp(z_k)}{\\sum_{i=1}^N\\exp(z_i)},\\quad \\text{ for }z=[z_1, z_2,\\ldots,z_N].\n\\] In the model, each \\(z_i=L_i(x)=\\theta^{(i)}_0+\\sum_{i=1}^n\\theta^{(i)}_ix_i,\\) has its own weights.\nThe related cost function is also updated:\n\\[\nJ(\\Theta)=-\\sum_{i=1}^Ny_k\\ln(p_i).\n\\] Therefore the same gradient descent algorithm can be applied.\n\n\n\n\n\n\nNote\n\n\n\nNote that sigmoid function and the binary crossentropy cost functions are the special case of softmax function.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe labels are not recorded as labels, but as vectors. This is called dummy variables, or one-hot encodings.\n\n\n\n\n5.4.3 Codes\n\nBoth LogisticRegression() and SGDClassifier() by default uses the one-vs-all naive idea.\nUsing kears, softmax can be implemented. The key configuration is the loss function loss='categorical_crossentropy' and the activation function softmax. Note that in this case the labels should be translated into one-hot vectors.\n\nWe use make_classification as an example. To save time we won’t carefully tune the hyperparameters here.\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\n\nX, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=2, n_repeated=2, n_classes=3, n_clusters_per_class=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n\nAlthough there are totally 10 features, the dataset can be visualized using the informative features. By description, the informative features are the first two.\n\nimport matplotlib.pyplot as plt\nplt.scatter(X[:, 0], X[:, 1], c=y)\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)\n\n0.8466666666666667\n\n\n\nfrom sklearn.linear_model import SGDClassifier\n\nclf = SGDClassifier()\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)\n\n0.8266666666666667\n\n\nTo apply keras package, we should first change y into one-hot vectors. Here we use the function provided by keras.\n\n# import keras_core as keras\nfrom keras.utils import to_categorical\nfrom keras import models, layers\n\nvy_train = to_categorical(y_train, num_classes=3)\nvy_test = to_categorical(y_test, num_classes=3)\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(3, activation='softmax', input_dim=10))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.fit(X_train, vy_train, epochs=50, batch_size=50, verbose=0)\n_ = model.evaluate(X_test, vy_test)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "contents/5/intro.html#exercises-and-projects",
    "href": "contents/5/intro.html#exercises-and-projects",
    "title": "5  Logistic regression",
    "section": "5.5 Exercises and Projects",
    "text": "5.5 Exercises and Projects\n\nExercise 5.1 Please hand write a report about the details of the math formulas for Logistic regression.\n\n\nExercise 5.2 CHOOSE ONE: Please use sklearn to apply the LogisticRegression to one of the following datasets. You may either use LogisticRegression or SGDClassifier.\n\nthe iris dataset.\nthe dating dataset.\nthe titanic dataset.\n\nPlease in addition answer the following questions.\n\nWhat is your accuracy score?\nHow many epochs do you use?\nPlot the learning curve (accuracy vs training sizes).\n\n\n\nExercise 5.3 CHOOSE ONE: Please use keras to apply the LogisticRegression to one of the following datasets.\n\nthe iris dataset.\nthe dating dataset.\nthe titanic dataset.\n\nPlease in addition answer the following questions.\n\nWhat is your accuracy score?\nHow many epochs do you use?\nWhat is the batch size do you use?\nPlot the learning curve (loss vs epochs, accuracy vs epochs).\nAnalyze the bias / variance status.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Logistic regression</span>"
    ]
  },
  {
    "objectID": "contents/6/intro.html#neural-network-back-propagation",
    "href": "contents/6/intro.html#neural-network-back-propagation",
    "title": "6  Netural networks",
    "section": "6.1 Neural network: Back propagation",
    "text": "6.1 Neural network: Back propagation\n\n\\[\n\\newcommand\\diffp[2]{\\dfrac{\\partial #1}{\\partial #2}}\n\\]\n\nTo train a MLP model, we still use gradient descent. Therefore it is very important to know how to compute the gradient. Actually the idea is the same as logistic regreesion. The only issue is that now the model is more complicated. The gradient computation is summrized as an algorithm called back propagation. It is described as follows.\nHere is an example of a Neural network with one hidden layer.\n\n\\(\\Theta\\) is the coefficients of the whole Neural network.\n\n\\(a^{(1)}=\\hat{\\textbf{x}}\\) is the input. \\(a_0^{(1)}\\) is added. This is an \\((n+1)\\)-dimension column vector.\n\\(\\Theta^{(1)}\\) is the coefficient matrix from the input layer to the hidden layer, of size \\(k\\times(n+1)\\).\n\\(z^{(2)}=\\Theta^{(1)}a^{(1)}\\).\n\\(a^{(2)}=\\sigma(z^{(2)})\\), and then add \\(a^{(2)}_0\\). This is an \\((k+1)\\)-dimension column vector.\n\\(\\Theta^{(2)}\\) is the coefficient matrix from the hidden layer to the output layer, of size \\(r\\times(k+1)\\).\n\\(z^{(3)}=\\Theta^{(2)}a^{(2)}\\).\n\\(a^{(3)}=\\sigma(z^{(3)})\\). Since this is the output layer, \\(a^{(3)}_0\\) won’t be added. %\nThese \\(a^{(3)}\\) are \\(h_{\\Theta}(\\textbf{x})\\).\n\nThe dependency is as follows:\n\n\\(J\\) depends on \\(z^{(3)}\\) and \\(a^{(3)}\\).\n\\(z^{(3)}\\) and \\(a^{(3)}\\) depends on \\(\\Theta^{(2)}\\) and \\(a^{(2)}\\).\n\\(z^{(2)}\\) and \\(a^{(2)}\\) depends on \\(\\Theta^{(1)}\\) and \\(a^{(1)}\\).\n\\(J\\) depends on \\(\\Theta^{(1)}\\), \\(\\Theta^{(2)}\\) and \\(a^{(1)}\\).\n\nEach layer is represented by the following diagram:\n\nThe diagram says:\n\\[\nz^{(k+1)}=b^{(k)}+\\Theta^{(k)}a^{(k)},\\quad z^{(k+1)}_j=b^{(k)}_j+\\sum \\Theta^{(k)}_{jl}a^{(k)}_l,\\quad a^{(k)}_j=\\sigma(z^{(k)}_j).\n\\]\nAssume \\(r,j\\geq1\\). Then\n\\[\n\\begin{aligned}\n\\diffp{z^{(k+1)}_i}{a^{(k)}_r}&=\\diffp*{\\left(b^{(k)}_i+\\sum\\Theta^{(k)}_{il}a^{(k)}_l\\right)}{a^{(k)}_r}=\\Theta_{ir}^{(k)},\\\\\n% \\diffp{z^{(k+1)}_i}{\\Theta^{(k)}_{ij}}&=\\diffp*{\\qty(a^{(k)}_0+\\sum\\Theta^{(k)}_{il}a^{(k)}_l)}{\\Theta^{(k)}_{ij}}=a^{(k)}_j,\\\\\n\\diffp{z^{(k+1)}_i}{z^{(k)}_j}&=\\sum_r \\diffp{z^{(k+1)}_i}{a^{k}_r}\\diffp{a^{(k)}_r}{z^{(k)}_j}+\\sum_{p,g}\\diffp{z^{(k+1)}_i}{\\Theta^{(k)}_{pq}}\\diffp{\\Theta^{(k)}_{pq}}{z^{(k)}_j}+\\sum_r \\diffp{z^{(k+1)}_i}{b^{k}_r}\\diffp{b^{(k)}_r}{z^{(k)}_j}\\\\\n&=\\sum_r \\Theta^{(k)}_{ir}\\diffp{a^{(k)}_r}{z^{(k)}_j}=\\Theta^{(k)}_{ij}\\diffp{a^{(k)}_j}{z^{(k)}_j}=\\Theta^{(k)}_{ij}\\sigma'(z^{(k)}_j),\\\\\n\\diffp{J}{z^{(k)}_j}&=\\sum_r \\diffp{J}{z^{(k+1)}_r}\\diffp{z^{(k+1)}_r}{z^{(k)}_j}=\\sum_r\\diffp{J}{z^{(k+1)}_r}\\Theta^{(k)}_{rj}\\sigma'(z^{(k)}_j).\n\\end{aligned}\n\\]\nWe set\n\n\\(\\delta^k_j=\\diffp{J}{z^{(k)}_j}\\), \\(\\delta^k=\\left[\\delta^k_1,\\delta_2^k,\\ldots\\right]^T\\).\n\\(\\mathbf{z}^k=\\left[z^{(k)}_1,z^{(k)}_2,\\ldots\\right]^T\\), \\(\\mathbf{a}^k=\\left[a^{(k)}_1,a^{(k)}_2,\\ldots\\right]^T\\), \\(\\hat{\\mathbf{a}}^k=\\left[a^{(k)}_0,a^{(k)}_1,\\ldots\\right]^T\\).\n\\(\\Theta^{k}=\\left[\\Theta^{(k)}_{ij}\\right]\\).\n\nThen we have the following formula. Note that there are ``\\(z_0\\)’’ terms.\n\\[\n    \\delta^k=\\left[(\\Theta^k)^T\\delta^{k+1}\\right]\\circ \\sigma'(\\mathbf{z}^k).\n\\]\n\\[\n\\begin{aligned}\n\\diffp{z^{(k+1)}_r}{\\Theta^{(k)}_{pq}}&=\\diffp*{\\left(b^{(k)}_r+\\sum_l\\Theta^{(k)}_{rl}a^{(k)}_l\\right)}{\\Theta^{(k)}_{pq}}=\\begin{cases}\n0&\\text{ for }r\\neq q,\\\\\na^{(k)}_q&\\text{ for }r=q,\n\\end{cases}\\\\\n\\diffp{J}{\\Theta^{(k)}_{pq}}&=\\sum_{r}\\diffp{J}{z^{(k+1)}_r}\\diffp{z^{(k+1)}_r}{\\Theta^{(k)}_{pq}}=\\diffp{J}{z^{(k+1)}_p}\\diffp{z^{(k+1)}_p}{\\Theta^{(k)}_{pq}}=\\delta^{k+1}_pa^{k}_q,\\\\\n\\diffp{J}{b^{(k)}_{j}}&=\\sum_{r}\\diffp{J}{z^{(k+1)}_r}\\diffp{z^{(k+1)}_r}{b^{(k)}_{j}}=\\diffp{J}{z^{(k+1)}_j}\\diffp{z^{(k+1)}_j}{b^{(k)}_{j}}=\\diffp{J}{z^{(k+1)}_j}=\\delta^{k+1}_j.\n\\end{aligned}\n\\]\nExtend \\(\\hat{\\Theta}=\\left[b^{(k)},\\Theta^{(k)}\\right]\\), and \\(\\partial^k J=\\left[\\diffp{J}{\\hat{\\Theta}^{(k)}_{ij}}\\right]\\). Then \\[\n    \\partial^k J=\\left[\\delta^{k+1}, \\delta^{k+1}(\\mathbf{a}^k)^T\\right].\n\\] Then the algorithm is as follows.\n\nStarting from \\(x\\), \\(y\\) and some random \\(\\Theta\\).\nForward computation: compute \\(z^{(k)}\\) and \\(a^{(k)}\\). The last \\(a^{(n)}\\) is \\(h\\).\nCompute \\(\\delta^n=\\nabla J\\circ\\sigma'(z^{(n)})\\). In the case of \\(J=\\frac12||{h-y}||^2\\), \\(\\nabla J=(a^{(n)}-y)\\), and then \\(\\delta^n=(a^{(n)}-y)\\circ\\sigma'(z^{(n)})\\).\nBackwards: \\(\\delta^k=\\left[(\\Theta^k)^T\\delta^{k+1}\\right]\\circ \\sigma'(\\mathbf{z}^k)\\), and \\(\\partial^k J=\\left[\\delta^{k+1}, \\delta^{k+1}(\\mathbf{a}^k)^T\\right]\\) .\n\n\nExample 6.1 Consider there are 3 layers: input, hidden and output. There are \\(m+1\\) nodes in the input layer, \\(n+1\\) nodes in the hidden layer and \\(k\\) in the output layer. Therefore\n\n\\(a^{(1)}\\) and \\(\\delta^1\\) are \\(m\\)-dim column vectors.\n\\(z^{(2)}\\), \\(a^{(2)}\\) and \\(\\delta^2\\) are \\(n\\)-dim column vectors.\n\\(z^{(3)}\\), \\(a^{(3)}\\) and \\(\\delta^3\\) are \\(k\\)-dim column vectors.\n\\(\\hat{\\Theta}^1\\) is \\(n\\times(m+1)\\), \\(\\hat{\\Theta}^2\\) is \\(k\\times(n+1)\\).\n\\(z^{(2)}=b^{(1)}+\\Theta^{(1)}a^{(1)}=\\hat{\\Theta}^{(1)}\\hat{a}^{(1)}\\), \\(z^{(3)}=b^{(2)}+\\Theta^{(2)}a^{(2)}=\\hat{\\Theta}^{(2)}\\hat{a}^{(2)}\\).\n\\(\\delta^3=\\nabla_aJ\\circ\\sigma'(z^{(3)})\\). This is a \\(k\\)-dim column vector.\n\\(\\partial^2 J=\\left[\\delta^3,\\delta^3(a^{(2)})^T\\right]\\).\n\\(\\delta^2=\\left[(\\Theta^2)^T\\delta^3\\right]\\circ \\sigma'(z^{(2)})\\), where \\((\\hat{\\Theta^2})^T\\delta^3=(\\hat{\\Theta^2})^T\\delta^3\\) and then remove the first row.\n\\(\\delta^1=\\begin{bmatrix}(\\Theta^1)^T\\delta^2\\end{bmatrix}\\circ \\sigma'(z^{(1)})\\), where \\((\\hat{\\Theta^1})^T\\delta^2=(\\hat{\\Theta^1})^T\\delta^2\\) and then remove the first row.\n\\(\\partial^1 J=\\left[\\delta^2,\\delta^2(a^{(1)})^T\\right]\\).\nWhen \\(J=-\\frac1m\\sum y\\ln a+(1-y)\\ln(1-a)\\), \\(\\delta^3=\\frac1m(\\sum a^{(3)}-\\sum y)\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Netural networks</span>"
    ]
  },
  {
    "objectID": "contents/6/intro.html#example",
    "href": "contents/6/intro.html#example",
    "title": "6  Netural networks",
    "section": "6.2 Example",
    "text": "6.2 Example\nLet us take some of our old dataset as an example. This is an continuation of the horse colic dataset from Logistic regression.\n\nimport pandas as pd\nimport numpy as np\n\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data'\ndf = pd.read_csv(url, delim_whitespace=True, header=None)\ndf = df.replace(\"?\", np.NaN)\n\ndf.fillna(0, inplace=True)\ndf.drop(columns=[2, 24, 25, 26, 27], inplace=True)\ndf[23].replace({1: 1, 2: 0}, inplace=True)\nX = df.iloc[:, :-1].to_numpy().astype(float)\ny = df[23].to_numpy().astype(int)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nmms = MinMaxScaler()\nmms.fit(X_train)\nX_train = mms.transform(X_train)\nX_test = mms.transform(X_test)\n\nNow we build a neural network. This is a 2-layer model, with 1 hidden layer with 10 nodes.\n\n# import keras_core as keras\nfrom keras import models, layers, Input\nmodel = models.Sequential()\n\nmodel.add(Input(shape=(X_train.shape[1],)))\nmodel.add(layers.Dense(10, activation='sigmoid'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhist = model.fit(X_train, y_train, epochs=500, batch_size=30, validation_data=(X_test, y_test), verbose=0)\n\nloss_train = hist.history['loss']\nloss_val = hist.history['val_loss']\n\nacc_train = hist.history['accuracy']\nacc_val = hist.history['val_accuracy']\n\nAnd the learning curve are shown in the following plots.\n\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 2)\nax[0].plot(loss_train, label='train_loss')\nax[0].plot(loss_val, label='val_loss')\nax[0].legend()\n\nax[1].plot(acc_train, label='train_acc')\nax[1].plot(acc_val, label='val_acc')\nax[1].legend()\n\n\n\n\n\n\n\n\nIt seems that our model has overfitting issues. Therefore we need to modifify the architects of our model. The first idea is to add L2 regularization as we talked about it in LogsiticRegression case. Here we use 0.01 as the regularization strenth.\nLet us add the layer to the model and retrain it.\n\n# import keras_core as keras\nfrom keras import regularizers\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(10, activation='sigmoid', input_dim=X_train.shape[1], kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhist = model.fit(X_train, y_train, epochs=500, batch_size=30, validation_data=(X_test, y_test), verbose=0)\n\nloss_train = hist.history['loss']\nloss_val = hist.history['val_loss']\n\nacc_train = hist.history['accuracy']\nacc_val = hist.history['val_accuracy']\n\n\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 2)\nax[0].plot(loss_train, label='train_loss')\nax[0].plot(loss_val, label='val_loss')\nax[0].legend()\n\nax[1].plot(acc_train, label='train_acc')\nax[1].plot(acc_val, label='val_acc')\nax[1].legend()\n\n\n\n\n\n\n\n\nAnother way to deal with overfitting is to add a Dropout layer. The idea is that when training the model, part of the data will be randomly discarded. Then after fitting, the model tends to reduce the variance, and then reduce the overfitting.\nThe code of a Dropout layer is listed below. Note that the number represents the percentage of the training data that will be dropped.\n\n# import keras_core as keras\nfrom keras import regularizers\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(10, activation='sigmoid', input_dim=X_train.shape[1]))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhist = model.fit(X_train, y_train, epochs=500, batch_size=30, validation_data=(X_test, y_test), verbose=0)\n\nloss_train = hist.history['loss']\nloss_val = hist.history['val_loss']\n\nacc_train = hist.history['accuracy']\nacc_val = hist.history['val_accuracy']\n\n\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 2)\nax[0].plot(loss_train, label='train_loss')\nax[0].plot(loss_val, label='val_loss')\nax[0].legend()\n\nax[1].plot(acc_train, label='train_acc')\nax[1].plot(acc_val, label='val_acc')\nax[1].legend()\n\n\n\n\n\n\n\n\nAfter playing with different hyperparameters, the overfitting issues seem to be better (but not entirely fixed). However, the overall performance is getting worse. This means that the model is moving towards underfitting side. Then we may add more layers to make the model more complicated in order to capture more information.\n\n# import keras_core as keras\nfrom keras import regularizers\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(10, activation='sigmoid', input_dim=X_train.shape[1]))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(10, activation='sigmoid', input_dim=X_train.shape[1]))\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhist = model.fit(X_train, y_train, epochs=500, batch_size=30, validation_data=(X_test, y_test), verbose=0)\n\nloss_train = hist.history['loss']\nloss_val = hist.history['val_loss']\n\nacc_train = hist.history['accuracy']\nacc_val = hist.history['val_accuracy']\n\n\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 2)\nax[0].plot(loss_train, label='train_loss')\nax[0].plot(loss_val, label='val_loss')\nax[0].legend()\n\nax[1].plot(acc_train, label='train_acc')\nax[1].plot(acc_val, label='val_acc')\nax[1].legend()\n\n\n\n\n\n\n\n\nAs you may see, to build a netural network model it requires many testing. There are many established models. When you build your own architecture, you may start from there and modify it to fit your data.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Netural networks</span>"
    ]
  },
  {
    "objectID": "contents/6/intro.html#exercises-and-projects",
    "href": "contents/6/intro.html#exercises-and-projects",
    "title": "6  Netural networks",
    "section": "6.3 Exercises and Projects",
    "text": "6.3 Exercises and Projects\n\nExercise 6.1 Please hand write a report about the details of back propagation.\n\n\nExercise 6.2 CHOOSE ONE: Please use netural network to one of the following datasets. - the iris dataset. - the dating dataset. - the titanic dataset.\nPlease in addition answer the following questions.\n\nWhat is your accuracy score?\nHow many epochs do you use?\nWhat is the batch size do you use?\nPlot the learning curve (loss vs epochs, accuracy vs epochs).\nAnalyze the bias / variance status.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Netural networks</span>"
    ]
  }
]