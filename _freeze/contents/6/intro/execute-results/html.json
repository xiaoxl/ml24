{
  "hash": "c807cfd03a2b83ff537dbe1fb745eb8a",
  "result": {
    "engine": "jupyter",
    "markdown": "# Logistic regression \n\nLogistic regression is very similar to linear regression, but applied to classification problems. In this chpater our idea is to treat it as the simplest example of a neural network instead of using other methods. The code we developped in the last chapter will be used extensively.\n\n<!-- \nConsider a set of training data $(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\ldots$, where $x^{(i)}=(x^{(i)}_1, x^{(i)}_2, \\ldots, x^{(i)}_n)$ is a $n$-dim vector, and $y^{(i)}$ is a real number. We would like to use Linear regression to find the relation between $x$ and $y$. \n\nIn this case, we assume that $y$ is a linear function of $x$:\n\n$$\ny=\\theta_0 + \\sum_{j=1}^n\\theta_jx_j.\n$$\nThe purpose of Linear regression is to used the given training data to find out the best $\\Theta=(\\theta_0, \\theta_1, \\theta_2,\\ldots,\\theta_n)$. \n\nIf we set $\\hat{x}=(1, x_1, \\ldots,x_n)$, then the above formula can be reformulated by matrix multiplication.\n\n$$\ny=\\Theta \\hat{x}^T.\n$$\n\nWhen we want to deal with classification problem, we may still use this regression idea, but we have to do some modification.\n -->\n\n\n\n\n\n\n\n## Basic idea\n\nAssume that we have a binary classfification problem with $N$ features. Our model starts from the *logit* instead of the label $y$ itself.\n\n$$\nlogit(y)=\\theta_0+\\sum_{j=1}^N\\theta_jx_j.\n$$\n\nThe logit function is used to describe the logorithm of the binary odds. The odd ratio is the ratio between the probability of success and the probability of failure. Assume the probability of success is $p$. Then \n\n$$\noddratio(p)=\\frac{p}{1-p},\\quad logit(p)=z = \\log\\qty(\\frac{p}{1-p}).\n$$\nWe could solve the logit function, and get its inverse: the function is the *Sigmoid* function. Once we have the logit value, we could use it to get the probability. \n$$\np=\\sigma(z)=\\frac{1}{1+\\mathrm{e}^{-z}}.\n$$\n<!-- \nThe Logsitic regression is used to predict the probability of a data point belonging to a specific class. It is based on linear regression. The major difference is that logistic regreesion will have an activation function $\\sigma$ at the final stage to change the predicted values of the linear regression to the values that indicate classes. In the case of binary classification, the outcome of $\\sigma$ will be between $0$ and $1$, which is related to the two classes respectively. In this case, the number is interepted as the probability of the data to be in one of the specific class. -->\n\n\n\nTherefore the model for Logistic regression is as follows:\n\n$$\np=\\sigma(L(x))=\\sigma\\left(\\theta_0+\\sum_{j=1}^n\\theta_jx_j\\right)=\\sigma\\left(\\Theta \\hat{x}^T\\right).\n$$\n\n<!-- In most cases, this activation function is chosen to be the Sigmoid funciton. -->\n\n### Sigmoid function\n\nThe *Sigmoid* function is defined as follows:\n\n$$\n\\sigma(z)=\\frac{1}{1+\\mathrm{e}^{-z}}.\n$$\nThe graph of the function is shown below.\n\n::: {#25a979dd .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-2-output-1.png){width=571 height=411}\n:::\n:::\n\n\nThe main properties of $\\sigma$ are listed below as a Lemma.\n\n\n::: {#lem-sig}\n\nThe Sigmoid function $\\sigma(z)$ satisfies the following properties.\n\n1. $\\sigma(z)\\rightarrow \\infty$ when $z\\mapsto \\infty$.\n2. $\\sigma(z)\\rightarrow -\\infty$ when $z\\mapsto -\\infty$.\n3. $\\sigma(0)=0.5$.\n4. $\\sigma(z)$ is always increasing.\n5. $\\sigma'(z)=\\sigma(z)(1-\\sigma(z))$.\n\n:::\n\n\n\n::: {.solution}\nWe will only look at the last one.\n\n$$\n\\begin{split}\n\\sigma'(z)&=-\\frac{(1+\\mathrm e^{-z})'}{(1+\\mathrm e^{-z})^2}=\\frac{\\mathrm e^{-z}}{(1+\\mathrm e^{-z})^2}=\\frac{1}{1+\\mathrm e^{-z}}\\frac{\\mathrm e^{-z}}{1+\\mathrm e^{-z}}\\\\\n&=\\sigma(z)\\left(\\frac{1+\\mathrm e^{-z}}{1+\\mathrm e^{-z}}-\\frac{1}{1+\\mathrm e^{-z}}\\right)=\\sigma(z)(1-\\sigma(z)).\n\\end{split}\n$$\n:::\n\n\n\n### Gradient descent\n<!-- Assume that we would like to minimize a function $J(\\Theta)$, where this $\\Theta$ is an $N$-dim vector. Geometricly, we could treat $J$ as a height function, and it tells us the height of the mountain. Then to minimize $J$ is the same thing as to find the lowest point. One idea is to move towards the lowest point step by step. During each step we only need to lower our current height. After several steps we will be around the lowest point.\n\nThe geometric meaning of $\\nabla J$ is the direction that $J$ increase the most. Therefore the opposite direction is the one we want to move in. The formula to update $x$ is \n\n$$\n\\Theta_{\\text{new}} = \\Theta_{\\text{old}}-\\alpha \\nabla J(\\Theta_{\\text{old}}),\n$$\nwhere $\\alpha$ is called the *learning rate* which controls how fast you want to learn. Usually if $\\alpha$ is small, the learning tends to be slow and stble, and when $\\alpha$ is big, the learning tends to be fast and unstable. -->\n\n<!-- In machine learning, in most cases we would like to formulate the problem in terms of finding the lowest point of a *cost function* $J(\\Theta)$.  -->\n\nWe would like to use Gradient descent to sovle Logistic regression problems. For binary classification problem, the cost function is defined to be\n\n$$\nJ(\\Theta)=-\\frac1m\\sum_{i=1}^m\\left[y^{(i)}\\log(p^{(i)})+(1-y^{(i)})\\log(1-p^{(i)})\\right].\n$$\nHere $m$ is the number of data points, $y^{(i)}$ is the labelled result (which is either $0$ or $1$), $p^{(i)}$ is the predicted value (which is between $0$ and $1$). \n\n::: {.callout-note}\nThe algorithm gets its name since we are using the gradient to find a direction to lower our height. \n:::\n\n\n### The Formulas\n\n\n::: {#thm-reggrad}\nThe gradient of $J$ is computed by\n\n$$\n\\nabla J =\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}.\n$$ {#eq-nablaJ}\n:::\n\n\n<details>\n<summary>Click for details.</summary>\n\n::: {.proof}\n\n\nThe formula is an application of the chain rule for the multivariable functions.\n\n$$\n\\begin{split}\n\\dfrac{\\partial p}{\\partial \\theta_k}&=\\dfrac{\\partial}{\\partial \\theta_k}\\sigma\\left(\\theta_0+\\sum_{j=1}^n\\theta_jx_j\\right)=\\dfrac{\\partial}{\\partial \\theta_k}\\sigma(L(\\Theta))\\\\\n&=\\sigma(L)(1-\\sigma(L))\\dfrac{\\partial}{\\partial \\theta_k}\\left(\\theta_0+\\sum_{j=1}^n\\theta_jx_j\\right)\\\\\n&=\\begin{cases}\np(1-p)&\\text{ if }k=0,\\\\\np(1-p)x_k&\\text{ otherwise}.\n\\end{cases}\n\\end{split}\n$$\nThen \n\n$$\n\\nabla p = \\left(\\frac{\\partial p}{\\partial\\theta_0},\\ldots,\\frac{\\partial p}{\\partial\\theta_n}\\right) = p(1-p)\\hat{x}.\n$$\n\nThen \n\n$$\n\\nabla \\log(p) = \\frac{\\nabla p}p =\\frac{p(1-p)\\hat{x}}{p}=(1-p)\\hat{x}.\n$$\n\n$$\n\\nabla \\log(1-p) = \\frac{-\\nabla p}{1-p} =-\\frac{p(1-p)\\hat{x}}{1-p}=-p\\hat{x}.\n$$\n\nThen \n\n$$\n\\begin{split}\n\\nabla J& = -\\frac1m\\sum_{i=1}^m\\left[y^{(i)}\\nabla \\log(p^{(i)})+(1-y^{(i)})\\nabla \\log(1-p^{(i)})\\right]\\\\\n&=-\\frac1m\\sum_{i=1}^m\\left[y^{(i)}(1-p^{(i)})\\hat{x}^{(i)}+(1-y^{(i)})(-p^{(i)}\\hat{x}^{(i)})\\right]\\\\\n&=-\\frac1m\\sum_{i=1}^m\\left[(y^{(i)}-p^{(i)})\\hat{x}^{(i)}\\right].\n\\end{split}\n$$\n\nWe write $\\hat{x}^{(i)}$ as row vectors, and stack all these row vectors vertically. What we get is a matrix $\\hat{\\textbf X}$ of the size $m\\times (1+n)$. We stack all $y^{(i)}$ (resp. $p^{(i)}$) vectically to get the $m$-dim column vector $\\textbf y$ (resp. $\\textbf p$). \n\nUsing this notation, the previous formula becomes\n\n\n$$\n\\nabla J =\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}.\n$$\n\nAfter the gradient can be computed, we can start to use the gradient descent method. Note that, although $\\Theta$ are not explicitly presented in the formula of $\\nabla J$, this is used to modify $\\Theta$:\n\n$$\n\\Theta_{s+1} = \\Theta_s - \\alpha\\nabla J.\n$$\n\n:::\n</details>\n\n\n::: {.callout-note}\nIf you directly use library, like `sklearn` or `PyTorch`, they will handle the concrete computation of these gradients.\n:::\n\n\n\n## Regularization\n\n### Three types of errors\nEvery estimator has its advantages and drawbacks. Its generalization error can be decomposed in terms of bias, variance and noise. The **bias** of an estimator is its average error for different training sets. The **variance** of an estimator indicates how sensitive it is to varying training sets. Noise is a property of the data. \n\n\n### Underfit vs Overfit\n\nWhen fit a model to data, it is highly possible that the model is underfit or overfit. \n\nRoughly speaking, **underfit** means the model is not sufficient to fit the training samples, and **overfit** means that the models learns too many noise from the data. In many cases, high bias is related to underfit, and high variance is related to overfit.\n\nThe following example is from [the `sklearn` guide](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html#sphx-glr-auto-examples-model-selection-plot-underfitting-overfitting-py). Although it is a polynomial regression example, it grasps the key idea of underfit and overfit.\n\n::: {#97609114 .cell .column-page execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-3-output-1.png){width=1079 height=445}\n:::\n:::\n\n\n### Learning curves (accuracy vs training size)\n\nA learning curve shows the validation and training score of an estimator for varying a key hyperparameter. In most cases the key hyperparameter is the training size or the number of epochs. It is a tool to find out how much we benefit from altering the hyperparameter by training more data or training for more epochs, and whether the estimator suffers more from a variance error or a bias error. \n\n`sklearn` provides `sklearn.model_selection.learning_curve()` to generate the values that are required to plot such a learning curve. However this function is just related to the sample size. If we would like to talk about epochs, we need other packages.\n\nLet us first look at the learning curve about sample size. The official document page is [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html). The function takes input `estimator`, dataset `X`, `y`, and an arry-like argument `train_sizes`. The dataset `(X, y)` will be split into pieces using the cross-validation technique. The number of pieces is set by the argument `cv`. The default value is `cv=5`. For details about cross-validation please see @sec-cross-validation.\n\nThen the model is trained over a random sample of the training set, and evaluate the score over the test set. The size of the sample of the training set is set by the argument `train_sizes`. This argument is array-like. Therefore the process will be repeated several times, and we can see the impact of increasing the training size. \n\nThe output contains three pieces. The first is `train_sizes_abs` which is the number of elements in each training set. This output is mainly for reference. The difference between the output and the input `train_sizes` is that the input can be float which represents the percentagy. The output is always the exact number of elements.\n\nThe second output is `train_scores` and the third is `test_scores`, both of which are the scores we get from the training and testing process. Note that both are 2D `numpy` arrays, of the size `(number of different sizes, cv)`. Each row is a 1D `numpy` array representing the cross-validation scores, which is corresponding to a train size. If we want the mean as the cross-validation score, we could use `train_scores.mean(axis=1)`.\n\nAfter understanding the input and output, we could plot the learning curve. We still use the `horse colic` as the example. The details about the dataset can be found [here](https://xiaoxl.github.io/Datasets/contents/horse_colic.html).\n\n::: {#38f42046 .cell execution_count=3}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data'\ndf = pd.read_csv(url, delim_whitespace=True, header=None)\ndf = df.replace(\"?\", np.NaN)\n\ndf.fillna(0, inplace=True)\ndf.drop(columns=[2, 24, 25, 26, 27], inplace=True)\ndf[23].replace({1: 1, 2: 0}, inplace=True)\nX = df.iloc[:, :-1].to_numpy().astype(float)\ny = df[23].to_numpy().astype(int)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Xinli\\AppData\\Local\\Temp\\ipykernel_6752\\73942173.py:5: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n  df = pd.read_csv(url, delim_whitespace=True, header=None)\nC:\\Users\\Xinli\\AppData\\Local\\Temp\\ipykernel_6752\\73942173.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[23].replace({1: 1, 2: 0}, inplace=True)\n```\n:::\n:::\n\n\nWe use the model `LogisticRegression`. The following code plot the learning curve for this model.\n\n::: {#deb71f56 .cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\n\nclf = LogisticRegression(max_iter=1000)\nsteps = [('scalar', MinMaxScaler()),\n         ('log', clf)]\npipe = Pipeline(steps=steps)\nfrom sklearn.model_selection import learning_curve\nimport numpy as np\ntrain_sizes, train_scores, test_scores = learning_curve(pipe, X_train, y_train,\n                                                        train_sizes=np.linspace(0.1, 1, 20))\n\nimport matplotlib.pyplot as plt\nplt.plot(train_sizes, train_scores.mean(axis=1), label='train')\nplt.plot(train_sizes, test_scores.mean(axis=1), label='test')\nplt.legend()\n```\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-5-output-1.png){width=579 height=411}\n:::\n:::\n\n\nThe learning curve is a primary tool for us to study the bias and variance. Usually\n\n- If the two training curve and the testing curve are very close to each other, this means that the variance is low. Otherwise the variance is high, and this means that the model probabily suffer from overfitting. \n- If the absolute training curve score is high, this means that the bias is low. Otherwise the bias is high, and this means that the model probabily suffer from underfitting.\n\nIn the above example, although regularization is applied by default, you may still notice some overfitting there.\n\n\n### Regularization\nRegularization is a technique to deal with overfitting. Here we only talk about the simplest method: ridge regression, also known as Tikhonov regularizaiton. Because of the formula given below, it is also called *$L_2$ regularization*. The idea is to add an additional term $\\dfrac{\\alpha}{2m}\\sum_{i=1}^m\\theta_i^2$ to the original cost function. When training with the new cost function, this additional term will force the parameters in the original term to be as small as possible. After finishing training, the additional term will be dropped, and we use the original cost function for validation and testing. Note that in the additional term $\\theta_0$ is not presented.\n\nThe hyperparameter $\\alpha$ is the *regularization strength*. If $\\alpha=0$, the new cost function becomes the original one; If $\\alpha$ is very large, the additional term dominates, and it will force all parameters to be almost $0$. In different context, the regularization strength is also given by $C=\\dfrac{1}{2\\alpha}$, called *inverse of regularization strength*.\n\n\n#### The math of regularization\n\n\n\n\n::: {#thm-ridgegrad}\nThe gradient of the ridge regression cost function is\n\n$$\n\\nabla J=\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}+\\frac{\\alpha}{m}\\Theta.\n$$\n\nNote that $\\Theta$ doesn't contain $\\theta_0$, or you may treat $\\theta_0=0$.\n\n:::\n\nThe computation is straightforward.\n\n#### The code\n\nRegularization is directly provided by the logistic regression functions.\n\n- In `LogisticRegression`, the regularization is given by the argument `penalty` and `C`. `penalty` specifies the regularizaiton method. It is `l2` by default, which is the method above. `C` is the inverse of regularization strength, whose default value is `1`.\n- In `SGDClassifier`, the regularization is given by the argument `penalty` and `alpha`. `penalty` is the same as that in `LogisticRegression`, and `alpha` is the regularization strength, whose default value is `0.0001`.\n\nLet us see the above example.\n\n::: {#1e7a97e9 .cell execution_count=5}\n``` {.python .cell-code}\nclf = LogisticRegression(max_iter=1000, C=0.1)\nsteps = [('scalar', MinMaxScaler()),\n         ('log', clf)]\npipe = Pipeline(steps=steps)\nfrom sklearn.model_selection import learning_curve\nimport numpy as np\ntrain_sizes, train_scores, test_scores = learning_curve(pipe, X_train, y_train,\n                                                        train_sizes=np.linspace(0.1, 1, 20))\n\nimport matplotlib.pyplot as plt\nplt.plot(train_sizes, train_scores.mean(axis=1), label='train')\nplt.plot(train_sizes, test_scores.mean(axis=1), label='test')\nplt.legend()\n```\n\n::: {.cell-output .cell-output-display}\n![](intro_files/figure-html/cell-6-output-1.png){width=588 height=411}\n:::\n:::\n\n\nAfter we reduce `C` from `1` to `0.1`, the regularization strength is increased. Then you may find that the gap between the two curves are reduced. However the overall performace is also reduced, from 85%~90% in `C=1` case to around 80% in `C=0.1` case. This means that the model doesn't fit the data well as the previous one. Therefore this is a trade-off: decrease the variance but increase the bias.\n\n\n## Neural network implement of Logistic regression\nIn the previous sections, we use gradient descent to run the Logistic regression model. We mentioned some important concepts, like epochs, mini-batch, etc.. We are going to use `PyTorch` to implement it. We will reuse many codes we wrote in the previous chapter.\n\n### A simple example\n\nWe \n\n$$f(x)$$\n\n\n\n### Example\n\nWe still use the horse colic dataset as an example. We first prepare the dataset.\n\n::: {#5e12731f .cell execution_count=6}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data'\ndf = pd.read_csv(url, sep='\\\\s+', header=None)\ndf = df.replace(\"?\", np.NaN)\n\ndf.fillna(0, inplace=True)\ndf = df.drop(columns=[2, 24, 25, 26, 27])\ndf[23] = df[23].replace({1: 1, 2: 0})\nX = df.iloc[:, :-1].to_numpy().astype(float)\ny = df[23].to_numpy().astype(int)\n\nSEED = 42\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=SEED)\n```\n:::\n\n\nWe need to perform normalization before throwing the data into the model. Here we use the `MinMaxScaler()` from `sklearn` package. \n\n::: {#94092d00 .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import MinMaxScaler\nmms = MinMaxScaler()\nX_train = mms.fit_transform(X_train, y_train)\nX_test = mms.transform(X_test)\n```\n:::\n\n\nThen we write a `Dataset` class to build the dataset and create the dataloaders. Since the set is already split, we don't need to `random_split` here.\n\n::: {#b95d2511 .cell execution_count=8}\n``` {.python .cell-code}\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass MyData(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=float)\n        self.y = torch.tensor(y, dtype=float).reshape(-1, 1)\n\n    def __getitem__(self, index):\n        return (self.X[index], self.y[index])\n\n    def __len__(self):\n        return len(self.y)\n\n\ntrain_set = MyData(X_train, y_train)\nval_set = MyData(X_test, y_test)\n\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=32)\n```\n:::\n\n\n\n\nIn the following code, we first set up the original model.\n\n::: {#15a760d9 .cell execution_count=10}\n``` {.python .cell-code}\nimport torch.nn as nn\nfrom torch.nn.modules import Linear\n\nclass LoR(nn.Module):\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self.linear = Linear(in_features=22, out_features=1, dtype=float)\n        self.activation = nn.Sigmoid()\n\n    def forward(self, X):\n        # pred = self.activation(self.linear(X))\n        pred = self.linear(X)\n        # return (pred >= 0).float()\n        return pred\n```\n:::\n\n\nThen we derive the base `ModelTemplate` class.\n\n::: {#37689a80 .cell execution_count=11}\n``` {.python .cell-code}\nclass LoRModel(ModelTemplate):\n    def __init__(self, model, loss_fn, optimizer):\n        super().__init__(model, loss_fn, optimizer)\n        self.stats['acc_train'] = []\n        self.stats['acc_val'] = []\n\n    def compute_acc(self, dataloader):\n        with torch.no_grad():\n            acc = []\n            for X_batch, y_batch in dataloader:\n                yhat = torch.sigmoid(self.model(X_batch))\n                y_pred = (yhat>=0.5).to(float)\n                acc.append((y_pred==y_batch).sum().item())\n            # print(acc_train)\n        return np.sum(acc)/len(dataloader.dataset)\n\n    def log_update(self, train_time, loss, val_time, val_loss, train_loader, val_loader):\n        super().log_update(train_time, loss, val_time, val_loss, train_loader, val_loader)\n        acc_train = self.compute_acc(train_loader)\n        acc_val = self.compute_acc(val_loader)\n        self.stats['acc_train'].append(acc_train)\n        self.stats['acc_val'].append(acc_val)\n\n\n        # p = self.model.state_dict()\n        # self.stats['acc'].append([p['linear.bias'].item(), p['linear.weight'].item()])\n\n    def log_output(self, verbose=0):\n        s = super().log_output(verbose=0, formatstr=':.6f')\n        s.append(f'acc_train: {self.stats['acc_train'][-1]:.6f}')\n        s.append(f'acc_val: {self.stats['acc_val'][-1]:.6f}')\n        # s.append(f'p: [{self.stats['p'][-1][0]:.6f}, {self.stats['p'][-1][1]:.6f}]')\n        if verbose == 1:\n            print(' '.join(s))\n        return s\n```\n:::\n\n\n::: {#5e3267a4 .cell execution_count=12}\n``` {.python .cell-code}\nfrom torch.optim import SGD\nfrom torch.nn import BCEWithLogitsLoss, BCELoss\n\noriginal_model = LoR()\nmodel = LoRModel(model=original_model, loss_fn=BCEWithLogitsLoss(),\n                 optimizer=SGD(original_model.parameters(), lr = 0.1))\n\nmodel.train(train_loader, val_loader, epoch_num=100, verbose=1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nepoch 1 train_time: 0.025606 loss: 0.663360 val_time: 0.001002 val_loss: 0.591178 acc_train: 0.627451 acc_val: 0.711111\nepoch 2 train_time: 0.006071 loss: 0.631373 val_time: 0.001022 val_loss: 0.577091 acc_train: 0.639216 acc_val: 0.688889\nepoch 3 train_time: 0.008528 loss: 0.616303 val_time: 0.001076 val_loss: 0.557480 acc_train: 0.635294 acc_val: 0.688889\nepoch 4 train_time: 0.008031 loss: 0.605392 val_time: 0.001004 val_loss: 0.549863 acc_train: 0.643137 acc_val: 0.711111\nepoch 5 train_time: 0.005993 loss: 0.596852 val_time: 0.001000 val_loss: 0.542675 acc_train: 0.670588 acc_val: 0.733333\nepoch 6 train_time: 0.007005 loss: 0.588852 val_time: 0.001004 val_loss: 0.536919 acc_train: 0.678431 acc_val: 0.755556\nepoch 7 train_time: 0.007016 loss: 0.580398 val_time: 0.000998 val_loss: 0.535554 acc_train: 0.694118 acc_val: 0.711111\nepoch 8 train_time: 0.008302 loss: 0.572577 val_time: 0.000505 val_loss: 0.531280 acc_train: 0.721569 acc_val: 0.733333\nepoch 9 train_time: 0.005508 loss: 0.567539 val_time: 0.000506 val_loss: 0.530978 acc_train: 0.709804 acc_val: 0.733333\nepoch 10 train_time: 0.005161 loss: 0.560500 val_time: 0.001089 val_loss: 0.525798 acc_train: 0.713725 acc_val: 0.733333\nepoch 11 train_time: 0.006593 loss: 0.554751 val_time: 0.002079 val_loss: 0.519992 acc_train: 0.717647 acc_val: 0.733333\nepoch 12 train_time: 0.008009 loss: 0.549918 val_time: 0.001499 val_loss: 0.516588 acc_train: 0.717647 acc_val: 0.711111\nepoch 13 train_time: 0.006690 loss: 0.545439 val_time: 0.000906 val_loss: 0.517100 acc_train: 0.741176 acc_val: 0.711111\nepoch 14 train_time: 0.010314 loss: 0.541090 val_time: 0.001424 val_loss: 0.516845 acc_train: 0.749020 acc_val: 0.711111\nepoch 15 train_time: 0.007023 loss: 0.538534 val_time: 0.000999 val_loss: 0.513026 acc_train: 0.752941 acc_val: 0.711111\nepoch 16 train_time: 0.005107 loss: 0.532256 val_time: 0.000996 val_loss: 0.510344 acc_train: 0.756863 acc_val: 0.711111\nepoch 17 train_time: 0.008003 loss: 0.528898 val_time: 0.001005 val_loss: 0.507357 acc_train: 0.756863 acc_val: 0.733333\nepoch 18 train_time: 0.009166 loss: 0.525083 val_time: 0.001002 val_loss: 0.506113 acc_train: 0.756863 acc_val: 0.755556\nepoch 19 train_time: 0.005005 loss: 0.521991 val_time: 0.001002 val_loss: 0.505801 acc_train: 0.760784 acc_val: 0.755556\nepoch 20 train_time: 0.006680 loss: 0.518048 val_time: 0.000590 val_loss: 0.504377 acc_train: 0.764706 acc_val: 0.755556\nepoch 21 train_time: 0.007628 loss: 0.515178 val_time: 0.000965 val_loss: 0.501788 acc_train: 0.764706 acc_val: 0.755556\nepoch 22 train_time: 0.006956 loss: 0.511985 val_time: 0.001001 val_loss: 0.498519 acc_train: 0.764706 acc_val: 0.755556\nepoch 23 train_time: 0.008291 loss: 0.510319 val_time: 0.001734 val_loss: 0.502694 acc_train: 0.776471 acc_val: 0.755556\nepoch 24 train_time: 0.008004 loss: 0.507094 val_time: 0.002007 val_loss: 0.498557 acc_train: 0.780392 acc_val: 0.755556\nepoch 25 train_time: 0.008541 loss: 0.504555 val_time: 0.001003 val_loss: 0.496031 acc_train: 0.780392 acc_val: 0.755556\nepoch 26 train_time: 0.008507 loss: 0.502874 val_time: 0.001231 val_loss: 0.497809 acc_train: 0.768627 acc_val: 0.777778\nepoch 27 train_time: 0.008026 loss: 0.499418 val_time: 0.002002 val_loss: 0.498013 acc_train: 0.768627 acc_val: 0.777778\nepoch 28 train_time: 0.008165 loss: 0.498026 val_time: 0.002274 val_loss: 0.492778 acc_train: 0.768627 acc_val: 0.755556\nepoch 29 train_time: 0.008006 loss: 0.495289 val_time: 0.002016 val_loss: 0.494707 acc_train: 0.768627 acc_val: 0.777778\nepoch 30 train_time: 0.008583 loss: 0.493465 val_time: 0.000997 val_loss: 0.491606 acc_train: 0.768627 acc_val: 0.777778\nepoch 31 train_time: 0.008539 loss: 0.492142 val_time: 0.001999 val_loss: 0.493763 acc_train: 0.776471 acc_val: 0.777778\nepoch 32 train_time: 0.010176 loss: 0.489031 val_time: 0.000856 val_loss: 0.487867 acc_train: 0.772549 acc_val: 0.755556\nepoch 33 train_time: 0.009514 loss: 0.487754 val_time: 0.001053 val_loss: 0.489957 acc_train: 0.784314 acc_val: 0.777778\nepoch 34 train_time: 0.009526 loss: 0.484993 val_time: 0.001504 val_loss: 0.490321 acc_train: 0.780392 acc_val: 0.800000\nepoch 35 train_time: 0.008076 loss: 0.483941 val_time: 0.000996 val_loss: 0.488905 acc_train: 0.784314 acc_val: 0.800000\nepoch 36 train_time: 0.010006 loss: 0.482123 val_time: 0.000999 val_loss: 0.490643 acc_train: 0.784314 acc_val: 0.822222\nepoch 37 train_time: 0.010026 loss: 0.479797 val_time: 0.001003 val_loss: 0.488573 acc_train: 0.784314 acc_val: 0.822222\nepoch 38 train_time: 0.009493 loss: 0.478553 val_time: 0.000999 val_loss: 0.488745 acc_train: 0.788235 acc_val: 0.822222\nepoch 39 train_time: 0.006038 loss: 0.476850 val_time: 0.002000 val_loss: 0.487375 acc_train: 0.788235 acc_val: 0.822222\nepoch 40 train_time: 0.009039 loss: 0.475686 val_time: 0.001009 val_loss: 0.485232 acc_train: 0.788235 acc_val: 0.822222\nepoch 41 train_time: 0.009015 loss: 0.474348 val_time: 0.000996 val_loss: 0.487242 acc_train: 0.784314 acc_val: 0.800000\nepoch 42 train_time: 0.009274 loss: 0.472675 val_time: 0.001738 val_loss: 0.486147 acc_train: 0.788235 acc_val: 0.800000\nepoch 43 train_time: 0.009037 loss: 0.470964 val_time: 0.001002 val_loss: 0.488879 acc_train: 0.792157 acc_val: 0.777778\nepoch 44 train_time: 0.010068 loss: 0.469322 val_time: 0.001001 val_loss: 0.484898 acc_train: 0.792157 acc_val: 0.800000\nepoch 45 train_time: 0.010699 loss: 0.467175 val_time: 0.000999 val_loss: 0.482207 acc_train: 0.792157 acc_val: 0.822222\nepoch 46 train_time: 0.008027 loss: 0.466430 val_time: 0.001025 val_loss: 0.483945 acc_train: 0.792157 acc_val: 0.777778\nepoch 47 train_time: 0.009001 loss: 0.465057 val_time: 0.000996 val_loss: 0.483917 acc_train: 0.792157 acc_val: 0.777778\nepoch 48 train_time: 0.009052 loss: 0.464450 val_time: 0.001504 val_loss: 0.483954 acc_train: 0.788235 acc_val: 0.777778\nepoch 49 train_time: 0.010130 loss: 0.462628 val_time: 0.001002 val_loss: 0.482258 acc_train: 0.788235 acc_val: 0.777778\nepoch 50 train_time: 0.009503 loss: 0.461465 val_time: 0.001581 val_loss: 0.480852 acc_train: 0.788235 acc_val: 0.777778\nepoch 51 train_time: 0.009676 loss: 0.460671 val_time: 0.001084 val_loss: 0.481887 acc_train: 0.784314 acc_val: 0.777778\nepoch 52 train_time: 0.007835 loss: 0.459667 val_time: 0.001024 val_loss: 0.483403 acc_train: 0.788235 acc_val: 0.777778\nepoch 53 train_time: 0.007568 loss: 0.458548 val_time: 0.001979 val_loss: 0.480798 acc_train: 0.788235 acc_val: 0.777778\nepoch 54 train_time: 0.007017 loss: 0.456605 val_time: 0.001015 val_loss: 0.476595 acc_train: 0.792157 acc_val: 0.800000\nepoch 55 train_time: 0.005991 loss: 0.455766 val_time: 0.001007 val_loss: 0.476254 acc_train: 0.788235 acc_val: 0.800000\nepoch 56 train_time: 0.006463 loss: 0.454364 val_time: 0.000703 val_loss: 0.475748 acc_train: 0.788235 acc_val: 0.800000\nepoch 57 train_time: 0.009217 loss: 0.453426 val_time: 0.001002 val_loss: 0.476889 acc_train: 0.788235 acc_val: 0.777778\nepoch 58 train_time: 0.008066 loss: 0.452996 val_time: 0.001039 val_loss: 0.472622 acc_train: 0.792157 acc_val: 0.800000\nepoch 59 train_time: 0.008023 loss: 0.450552 val_time: 0.000999 val_loss: 0.473983 acc_train: 0.788235 acc_val: 0.800000\nepoch 60 train_time: 0.006008 loss: 0.450961 val_time: 0.000998 val_loss: 0.475729 acc_train: 0.792157 acc_val: 0.777778\nepoch 61 train_time: 0.006899 loss: 0.449198 val_time: 0.000994 val_loss: 0.474061 acc_train: 0.796078 acc_val: 0.800000\nepoch 62 train_time: 0.007809 loss: 0.449090 val_time: 0.000985 val_loss: 0.472522 acc_train: 0.796078 acc_val: 0.800000\nepoch 63 train_time: 0.007504 loss: 0.447263 val_time: 0.001161 val_loss: 0.472199 acc_train: 0.800000 acc_val: 0.800000\nepoch 64 train_time: 0.007024 loss: 0.448118 val_time: 0.001000 val_loss: 0.471866 acc_train: 0.800000 acc_val: 0.800000\nepoch 65 train_time: 0.007375 loss: 0.445791 val_time: 0.002005 val_loss: 0.473116 acc_train: 0.800000 acc_val: 0.800000\nepoch 66 train_time: 0.008109 loss: 0.444859 val_time: 0.001000 val_loss: 0.471130 acc_train: 0.800000 acc_val: 0.800000\nepoch 67 train_time: 0.008872 loss: 0.444836 val_time: 0.001008 val_loss: 0.476986 acc_train: 0.792157 acc_val: 0.755556\nepoch 68 train_time: 0.008024 loss: 0.443869 val_time: 0.001015 val_loss: 0.477343 acc_train: 0.792157 acc_val: 0.755556\nepoch 69 train_time: 0.008382 loss: 0.442003 val_time: 0.000872 val_loss: 0.472406 acc_train: 0.796078 acc_val: 0.777778\nepoch 70 train_time: 0.008015 loss: 0.442441 val_time: 0.002018 val_loss: 0.472517 acc_train: 0.796078 acc_val: 0.755556\nepoch 71 train_time: 0.008495 loss: 0.440051 val_time: 0.001003 val_loss: 0.471328 acc_train: 0.800000 acc_val: 0.800000\nepoch 72 train_time: 0.006979 loss: 0.439677 val_time: 0.001505 val_loss: 0.471477 acc_train: 0.796078 acc_val: 0.777778\nepoch 73 train_time: 0.006435 loss: 0.438054 val_time: 0.000905 val_loss: 0.470089 acc_train: 0.800000 acc_val: 0.800000\nepoch 74 train_time: 0.008073 loss: 0.438404 val_time: 0.000000 val_loss: 0.470556 acc_train: 0.800000 acc_val: 0.777778\nepoch 75 train_time: 0.006691 loss: 0.436705 val_time: 0.000000 val_loss: 0.471770 acc_train: 0.792157 acc_val: 0.755556\nepoch 76 train_time: 0.008034 loss: 0.436370 val_time: 0.001999 val_loss: 0.469594 acc_train: 0.800000 acc_val: 0.777778\nepoch 77 train_time: 0.005794 loss: 0.435692 val_time: 0.001001 val_loss: 0.472588 acc_train: 0.792157 acc_val: 0.755556\nepoch 78 train_time: 0.005000 loss: 0.436305 val_time: 0.002022 val_loss: 0.472771 acc_train: 0.792157 acc_val: 0.755556\nepoch 79 train_time: 0.005075 loss: 0.433062 val_time: 0.001032 val_loss: 0.469406 acc_train: 0.792157 acc_val: 0.777778\nepoch 80 train_time: 0.007174 loss: 0.433353 val_time: 0.001006 val_loss: 0.470874 acc_train: 0.792157 acc_val: 0.755556\nepoch 81 train_time: 0.009022 loss: 0.432955 val_time: 0.001170 val_loss: 0.467601 acc_train: 0.796078 acc_val: 0.777778\nepoch 82 train_time: 0.007017 loss: 0.432032 val_time: 0.001004 val_loss: 0.466190 acc_train: 0.800000 acc_val: 0.777778\nepoch 83 train_time: 0.007920 loss: 0.430732 val_time: 0.001468 val_loss: 0.468723 acc_train: 0.792157 acc_val: 0.777778\nepoch 84 train_time: 0.007699 loss: 0.430406 val_time: 0.001978 val_loss: 0.466793 acc_train: 0.796078 acc_val: 0.777778\nepoch 85 train_time: 0.009265 loss: 0.431159 val_time: 0.000821 val_loss: 0.469345 acc_train: 0.792157 acc_val: 0.755556\nepoch 86 train_time: 0.008067 loss: 0.428412 val_time: 0.001077 val_loss: 0.467226 acc_train: 0.796078 acc_val: 0.777778\nepoch 87 train_time: 0.008578 loss: 0.429025 val_time: 0.001000 val_loss: 0.470651 acc_train: 0.803922 acc_val: 0.755556\nepoch 88 train_time: 0.009015 loss: 0.427135 val_time: 0.001155 val_loss: 0.467216 acc_train: 0.796078 acc_val: 0.777778\nepoch 89 train_time: 0.009193 loss: 0.426490 val_time: 0.000000 val_loss: 0.465963 acc_train: 0.796078 acc_val: 0.777778\nepoch 90 train_time: 0.008144 loss: 0.425522 val_time: 0.001079 val_loss: 0.465590 acc_train: 0.796078 acc_val: 0.777778\nepoch 91 train_time: 0.008127 loss: 0.425849 val_time: 0.000996 val_loss: 0.465986 acc_train: 0.800000 acc_val: 0.777778\nepoch 92 train_time: 0.008022 loss: 0.424761 val_time: 0.002000 val_loss: 0.465338 acc_train: 0.800000 acc_val: 0.777778\nepoch 93 train_time: 0.008014 loss: 0.424103 val_time: 0.001000 val_loss: 0.465394 acc_train: 0.803922 acc_val: 0.777778\nepoch 94 train_time: 0.008154 loss: 0.425253 val_time: 0.001062 val_loss: 0.465525 acc_train: 0.803922 acc_val: 0.777778\nepoch 95 train_time: 0.008005 loss: 0.422772 val_time: 0.000000 val_loss: 0.463979 acc_train: 0.800000 acc_val: 0.777778\nepoch 96 train_time: 0.007298 loss: 0.422950 val_time: 0.000740 val_loss: 0.465250 acc_train: 0.807843 acc_val: 0.777778\nepoch 97 train_time: 0.006181 loss: 0.421875 val_time: 0.002000 val_loss: 0.462000 acc_train: 0.792157 acc_val: 0.777778\nepoch 98 train_time: 0.006994 loss: 0.420906 val_time: 0.001503 val_loss: 0.460044 acc_train: 0.788235 acc_val: 0.777778\nepoch 99 train_time: 0.007023 loss: 0.421845 val_time: 0.001000 val_loss: 0.460713 acc_train: 0.792157 acc_val: 0.777778\nepoch 100 train_time: 0.006095 loss: 0.420074 val_time: 0.001045 val_loss: 0.460142 acc_train: 0.792157 acc_val: 0.777778\n```\n:::\n:::\n\n\n## Pytorch crash course\n\n\n\n### Tensor\n\nThis is the basic data structure. It is very similar to `numpy.ndarray`, but with many more features. There are a few things that we need to mention at the beginning.\n\n1. A tensor with only one item is mathematically equal to a number. In Pytorch, you may use `.item()` to extract the number from a tensor with only one item.\n\n::: {#bd288c49 .cell execution_count=13}\n``` {.python .cell-code}\nimport torch\n\na = torch.tensor([1])\na\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\ntensor([1])\n```\n:::\n:::\n\n\n::: {#c529184b .cell execution_count=14}\n``` {.python .cell-code}\na.item()\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n1\n```\n:::\n:::\n\n\n2. It is type sensitive. Pytorch expect you to assign the exact data type to each tensor, and it won't automatically guess it in most cases. You may specify data type when you create a tensor.\n\n::: {#348676a7 .cell execution_count=15}\n``` {.python .cell-code}\nb = torch.tensor([1], dtype=torch.float64)\nb\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\ntensor([1.], dtype=torch.float64)\n```\n:::\n:::\n\n\nIf you want to convert data type, you could use `.to()`.\n\n::: {#5699a119 .cell execution_count=16}\n``` {.python .cell-code}\nb = torch.tensor([1], dtype=torch.float64)\nb = b.to(torch.int)\nb\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\ntensor([1], dtype=torch.int32)\n```\n:::\n:::\n\n\nTensor data structure has many other features that will be introduced later.\n\n\n### Gradient descent\n\nTo implement the gradient descent algorithm for the neural network, there would be a series of computations:\n\n1. From the input, feedforward the network to get the output `y_pred`.\n2. Based on the real output `y_true`, compute the loss function `loss = loss_fn(y_true, y_pred)`.\n3. Compute the gradient based on the information provided. For this step many data are needed. You may look up the gradient descent formula (backprop).\n4. Based on the gradient computed in Step 3, weights are updated, according to the optimizer we choose.\n\nIn Pytorch, the above steps are implemented as follows.\n\n1. You have to define a `model` function to indicate how to feedforward the network to get an output. Here for a lot of reasons, the typical way is to define a `model` class, which contains a `forward` method that can compute the output of the model. Let us consider the following example: the dataset is as follows:\n\n::: {#84889b98 .cell execution_count=17}\n``` {.python .cell-code}\nx = torch.tensor([[1, 2], [3, 4], [0, 1]], dtype=torch.float)\ny = torch.tensor([[3], [7], [1]], dtype=torch.float)\n```\n:::\n\n\nThe model is defined as follows.\n\n::: {#c89deadf .cell execution_count=18}\n``` {.python .cell-code}\nimport torch.nn as nn\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n\n        self.fc = nn.Linear(in_features=2, out_features=1)\n    \n    def forward(self, x):\n        x = self.fc(x)\n        return x\n```\n:::\n\n\nIn this example, we define a 2-input linear regression model. Pytorch doesn't need the class to work. Actually the minimal working example of the above code is as follows. To put things into a class can make it easier in larger models. \n\n::: {#e42ffb99 .cell execution_count=19}\n``` {.python .cell-code}\ndef model(x):\n    return nn.Linear(in_features=2, out_features=1)(x)\n```\n:::\n\n\nThe reason the model can be written in a very simple way is because the information about computing gradients is recorded in the parameter tensors, on the level of tensors, instead of on the level of the model class. Therefore it is important to get access to the parameters of the model. \n\n::: {#871fd8fe .cell execution_count=20}\n``` {.python .cell-code}\nmodel = MyModel()\nlist(model.parameters())\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n[Parameter containing:\n tensor([[-0.3573, -0.2246]], requires_grad=True),\n Parameter containing:\n tensor([-0.2558], requires_grad=True)]\n```\n:::\n:::\n\n\nNote that the parameters we get here is a iterator. So to look at it we need to convert it inot a list. In this example, there are two sets of tensors: the first is the coefficients, and the second is the bias term. This bias term can be turned on/off by setting the argument `bias=True` or `False` when using `nn.Linear()` to create fully connected layers. The default is `True`.\n\nTo evaluate the model, we just directly apply the model to the input tensor.\n\n::: {#3cd41874 .cell execution_count=21}\n``` {.python .cell-code}\ny_pred = model(x)\ny_pred\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\ntensor([[-1.0623],\n        [-2.2262],\n        [-0.4804]], grad_fn=<AddmmBackward0>)\n```\n:::\n:::\n\n\nYou may use the coefficients provided above to validate the resutl.\n\nNote that, although we define the `.forward()` method, we don't use it explicitly. The reason is that `model(x)` will not only excute `.forward(x)` method, but many other operations, like recording many intermediate results that can be used for debugging, visualization and modifying gradients.\n\n\n2. We may define the loss function. We mannually define the MSE loss function.\n\n::: {#1bf3d8b4 .cell execution_count=22}\n``` {.python .cell-code}\ndef loss_fn(y_true, y_pred):\n    return ((y_true-y_pred)**2).mean()\n\nloss = loss_fn(y, y_pred)\nloss\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\ntensor(34.6054, grad_fn=<MeanBackward0>)\n```\n:::\n:::\n\n\n3. Now we need to do gradient descent. The manual way to `loss.backward()`. What it does is to \n\n::: {#71b2c461 .cell execution_count=23}\n``` {.python .cell-code}\nprint(list(model.parameters()))\nprint(list(model.parameters())[0].grad)\nprint(list(model.parameters())[1].grad)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[Parameter containing:\ntensor([[-0.3573, -0.2246]], requires_grad=True), Parameter containing:\ntensor([-0.2558], requires_grad=True)]\nNone\nNone\n```\n:::\n:::\n\n\n::: {#3a648a16 .cell execution_count=24}\n``` {.python .cell-code}\nimport torch.optim as optim\noptimizer = optim.SGD(model.parameters(), lr=1e-2)\n```\n:::\n\n\n::: {#a131b202 .cell execution_count=25}\n``` {.python .cell-code}\nloss.backward()\noptimizer.step()\n\n```\n:::\n\n\n::: {#ec470ef9 .cell execution_count=26}\n``` {.python .cell-code}\nfor i in range(100):\n    optimizer.zero_grad()\n    # print(optimizer.param_groups)\n\n    y_pred = model(x)\n    loss = loss_fn(y_pred, y)\n\n    # print(optimizer.param_groups)\n\n    loss.backward()\n    optimizer.step()\n\n    # print(optimizer.param_groups)\n\n    # print(list(model.parameters()))\n    # print(list(model.parameters())[0].grad)\n    # print(list(model.parameters())[1].grad)\n```\n:::\n\n\n4. Update the parameters by `optim` or manually done.\n\n### Mini-batch\n\n\n\n\n\n\n<!-- {{< include multi.qmd >}} -->\n\n\n\n\n### Codes\nWe will only talk about using packages. `sklearn` provides two methods to implement the Logistic regression. The API interface is very similar to other models. Later we will use `PyTorch` and our\n\nNote that Logistic regression is very sensitive to the scale of features. Therefore we need to normalize the features before throwing them into the model.\n\nLet's still take `iris` as an example.\n\n::: {#fa32610b .cell execution_count=27}\n``` {.python .cell-code}\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\n\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n```\n:::\n\n\nThe first method is `sklearn.linear_model.LogisticRegression`. \n\n::: {#5118d249 .cell execution_count=28}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\nsteps = [('normalize', MinMaxScaler()),\n         ('log', LogisticRegression())]\n\nlog_reg = Pipeline(steps=steps)\nlog_reg.fit(X_train, y_train)\nlog_reg.score(X_test, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\n0.9565217391304348\n```\n:::\n:::\n\n\nNote that this method has an option `solver` that will set the way to solve the Logistic regression problem, and there is no \"stochastic gradient descent\" provided. The default solver for this `LogsiticRegression` is `lbfgs` which will NOT be discussed in lectures.\n\nThe second method is `sklearn.linear_model.SGDClassifier`.\n\n::: {#5eeb8b8b .cell execution_count=29}\n``` {.python .cell-code}\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\nsteps = [('normalize', MinMaxScaler()),\n         ('log', SGDClassifier(loss='log_loss', max_iter=100))]\n\nsgd_clf = Pipeline(steps=steps)\nsgd_clf.fit(X_train, y_train)\nsgd_clf.score(X_test, y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\n0.9565217391304348\n```\n:::\n:::\n\n\nThis method is the one we discussed in lectures. The `log_loss` loss function is the binary entropy function we mentioned in lectures. If you change to other loss functions it will become other models.\n\nFrom the above example, you may notice that `SGDClassifier` doesn't perform as well as `LogisticRegression`. This is due to the algorithm. To make `SGDClassifier` better you need to tune the hyperparameters, like `max_iter`, `learning_rate`/`alpha`, `penalty`, etc..\n\n\n\n::: {.callout-note}\nThe argument `warm_start` is used to set whether you want to use your previous model. When set to `True`, it will reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. The default is `False`.  \n\nRepeatedly calling `fit` when `warm_start` is `True` can result in a different solution than when calling `fit` a single time because of the way the data is shuffled. \n:::\n\n\n::: {.callout-note}\n\nNote that for both methods, regularization (which will be discussed later) is applied by default.\n:::\n\n\n### Several important side topics\n\n#### Epochs\nWe use epoch to describe feeding data into the model. One *Epoch* is when an entire dataset is passed through the model once. When using gradient descent, we tend to run several epochs. The number of maximal epochs is one important hyperparameter of this model.\n\nThe general idea is that more epochs are better for the score of the model, but it will definitely be slower. In addition, sometimes due to many other factors, after a few epochs, the model becomes stall. To train for more epochs cannot improve the model. In this case you have to turn to other methods.\n\n\n#### Batch Gradient Descent vs SGD vs Minibatch\nRecall the Formula @eq-nablaJ: \n\n$$\n\\nabla J =\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}.\n$$\nWe could rewrite this formula:\n\n$$\n\\nabla J =\\frac1m(\\textbf{p}-\\textbf{y})^T\\hat{\\textbf{X}}=\\frac1m\\sum_{i=1}^m\\left[(p^{(i)}-y^{(i)})\\hat{x}^{(i)}\\right].\n$$\nThis new formula can be understood in the following way: For every data point, we could get one gradient direction. Then $\\nabla J$ is the average of all gradient directions. So this algorithm can be expressed as that compute the gradient for every data points and then take the average, and finally update the parameters once. This algorithm is called *batch gradient descent*. \n\n\nFollowing the idea, there is another way to update the model. For every data point, we could compute one gradient direction, and we could use the gradient direction to update the parameters of the model. This algorithm is called *stochastic gradient descent*. \n\nThen there is an algrothm living in the middle, called *mini-batch gradient descent*. In this case, we will group the data set into a collection of subsets of a fiexed number of training examples. Each subset is called a *mini-batch*, and the fixed number of elements of each mini-batch is called the *batch size*. Using this method, we will just go through mini-batches one at a time, compute the average of the gradient for these data, and then update the parameters of the model after we finish one mini-batch. Assume that the total number of the dataset is `N`, the mini-batch size is `m`. Then there are `N/m` mini-batches, and during one epoch we will update the model `N/m` times.\n\n\nMini-batch size is one important hyperparameters of this model. Usually the larger the batch size is, the less variance the model has. Then it tends to behave more smoothly, but it will also be slower, and might be stuck to a local minimal. The smaller batch size is more chaotic. It might go faster, but it tends not to converge.\n\n\n\n\n\n## Exercises and Projects\n\n\n\n::: {#exr-}\nPlease hand write a report about the details of the math formulas for Logistic regression.\n:::\n\n\n\n\n::: {#exr-}\nCHOOSE ONE: Please use `sklearn` to apply the LogisticRegression to one of the following datasets. You may either use `LogisticRegression` or `SGDClassifier`.\n\n- the `iris` dataset.\n- the dating dataset.\n- the `titanic` dataset.\n\nPlease in addition answer the following questions.\n\n1. What is your accuracy score?\n2. How many epochs do you use?\n3. Plot the learning curve (accuracy vs training sizes).\n:::\n\n\n\n::: {#exr-}\n\nCHOOSE ONE: Please use `keras` to apply the LogisticRegression to one of the following datasets.\n\n- the `iris` dataset.\n- the dating dataset.\n- the `titanic` dataset.\n\nPlease in addition answer the following questions.\n\n1. What is your accuracy score?\n2. How many epochs do you use?\n3. What is the batch size do you use?\n4. Plot the learning curve (loss vs epochs, accuracy vs epochs).\n5. Analyze the bias / variance status.\n\n\n:::\n\n",
    "supporting": [
      "intro_files"
    ],
    "filters": [],
    "includes": {}
  }
}